{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "540bae9d",
   "metadata": {},
   "source": [
    "**dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7314ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af7a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_epochs = 150\n",
    "learning_rate = 0.002\n",
    "threshold = 0.0011706234052549184\n",
    "classes = ['abnormal','normal']\n",
    "\n",
    "cnn_err_rate = []\n",
    "ae_err_rate = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c6c6ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\CNN_dataset10',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_loader1 = torch.utils.data.DataLoader(dataset1, batch_size=batch_size)\n",
    "test_loader1 = torch.utils.data.DataLoader(dataset1, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223fe3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\CNN_dataset30',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_loader2 = torch.utils.data.DataLoader(dataset2, batch_size=batch_size)\n",
    "test_loader2 = torch.utils.data.DataLoader(dataset2, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aef99ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\CNN_dataset60',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_loader3 = torch.utils.data.DataLoader(dataset3, batch_size=batch_size)\n",
    "test_loader3 = torch.utils.data.DataLoader(dataset3, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0896731",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4 = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\CNN_dataset90',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_loader4 = torch.utils.data.DataLoader(dataset4, batch_size=batch_size)\n",
    "test_loader4 = torch.utils.data.DataLoader(dataset4, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a496974",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset5 = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\CNN_dataset120',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_loader5 = torch.utils.data.DataLoader(dataset5, batch_size=batch_size)\n",
    "test_loader5 = torch.utils.data.DataLoader(dataset5, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae7cbcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset6 = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\CNN_dataset150',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_loader6 = torch.utils.data.DataLoader(dataset6, batch_size=batch_size)\n",
    "test_loader6 = torch.utils.data.DataLoader(dataset6, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1dfc195",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset7 = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\CNN_dataset230',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_loader7 = torch.utils.data.DataLoader(dataset7, batch_size=batch_size)\n",
    "test_loader7 = torch.utils.data.DataLoader(dataset7, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84c7a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset8 = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\CNN_dataset300',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_loader8 = torch.utils.data.DataLoader(dataset8, batch_size=batch_size)\n",
    "test_loader8 = torch.utils.data.DataLoader(dataset8, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0459373d",
   "metadata": {},
   "source": [
    "**CNN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1572009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 12, 5) \n",
    "        self.conv3 = nn.Conv2d(12, 24, 4)  \n",
    "        self.fc1 = nn.Linear(24 * 25 * 25, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # 6 * 110 * 110\n",
    "        x = self.pool(F.relu(self.conv2(x))) # 12 * 53 * 53\n",
    "        x = self.pool(F.relu(self.conv3(x))) # 24 * 25 * 25\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "cnn1 = CNN()\n",
    "cnn2 = CNN()\n",
    "cnn3 = CNN()\n",
    "cnn4 = CNN()\n",
    "cnn5 = CNN()\n",
    "cnn6 = CNN()\n",
    "cnn7 = CNN()\n",
    "cnn8 = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "894c6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_criterion = nn.CrossEntropyLoss()\n",
    "optimizer1 = torch.optim.SGD(cnn1.parameters(), lr=learning_rate)\n",
    "optimizer2 = torch.optim.SGD(cnn2.parameters(), lr=learning_rate)\n",
    "optimizer3 = torch.optim.SGD(cnn3.parameters(), lr=learning_rate)\n",
    "optimizer4 = torch.optim.SGD(cnn4.parameters(), lr=learning_rate)\n",
    "optimizer5 = torch.optim.SGD(cnn5.parameters(), lr=learning_rate)\n",
    "optimizer6 = torch.optim.SGD(cnn6.parameters(), lr=learning_rate)\n",
    "optimizer7 = torch.optim.SGD(cnn7.parameters(), lr=learning_rate)\n",
    "optimizer8 = torch.optim.SGD(cnn8.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b0ab0",
   "metadata": {},
   "source": [
    "***CAE model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73390e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_set1 = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\abnormal10',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "abnormal_loader1 = torch.utils.data.DataLoader(abnormal_set1, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4edc8779",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_set2 = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\abnormal30',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "abnormal_loader2 = torch.utils.data.DataLoader(abnormal_set2, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79154827",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_set3 = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\abnormal60',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "abnormal_loader3 = torch.utils.data.DataLoader(abnormal_set3, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41e97039",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_set4 = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\abnormal90',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "abnormal_loader4 = torch.utils.data.DataLoader(abnormal_set4, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0922249",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_set5 = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\abnormal120',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "abnormal_loader5 = torch.utils.data.DataLoader(abnormal_set5, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e356fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_set6 = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\abnormal150',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "abnormal_loader6 = torch.utils.data.DataLoader(abnormal_set6, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efd0d63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_set7 = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\abnormal230',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "abnormal_loader7 = torch.utils.data.DataLoader(abnormal_set7, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a346ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_set8 = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\abnormal300',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "abnormal_loader8 = torch.utils.data.DataLoader(abnormal_set8, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "293c28ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.cnn_layer1 = nn.Sequential(\n",
    "                        nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                         nn.MaxPool2d(2,2))\n",
    "\n",
    "        self.cnn_layer2 = nn.Sequential(\n",
    "                                nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                 nn.MaxPool2d(2,2))\n",
    "        \n",
    "        self.cnn_layer3 = nn.Sequential(\n",
    "                                nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                 nn.MaxPool2d(2,2))\n",
    "\n",
    "        # Decoder        \n",
    "        self.tran_cnn_layer1 = nn.Sequential(\n",
    "                        nn.ConvTranspose2d(64, 32, kernel_size = 2, stride = 2, padding=0),\n",
    "                        nn.ReLU())\n",
    "        \n",
    "        self.tran_cnn_layer2 = nn.Sequential(\n",
    "                        nn.ConvTranspose2d(32, 16, kernel_size = 2, stride = 2, padding=0),\n",
    "                        nn.ReLU())\n",
    "\n",
    "        self.tran_cnn_layer3 = nn.Sequential(\n",
    "                        nn.ConvTranspose2d(16, 3, kernel_size = 2, stride = 2, padding=0),\n",
    "                        nn.Sigmoid())  \n",
    "            \n",
    "    def forward(self, x):\n",
    "        output = self.cnn_layer1(x)\n",
    "        output = self.cnn_layer2(output)\n",
    "        output = self.cnn_layer3(output)        \n",
    "        output = self.tran_cnn_layer1(output)\n",
    "        output = self.tran_cnn_layer2(output)\n",
    "        output = self.tran_cnn_layer3(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da949680",
   "metadata": {},
   "outputs": [],
   "source": [
    "AE = ConvAutoEncoder()\n",
    "AE.load_state_dict(torch.load('best_model_final.pth'))\n",
    "ae_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d603f783",
   "metadata": {},
   "source": [
    "***train(10)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb958247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,   150] loss: 0.6695609\n",
      "[1,   150] loss: 0.6631767\n",
      "[2,   150] loss: 0.6569503\n",
      "[3,   150] loss: 0.6506744\n",
      "[4,   150] loss: 0.6442241\n",
      "[5,   150] loss: 0.6376924\n",
      "[6,   150] loss: 0.6309495\n",
      "[7,   150] loss: 0.6237357\n",
      "[8,   150] loss: 0.6156825\n",
      "[9,   150] loss: 0.6067864\n",
      "[10,   150] loss: 0.5974369\n",
      "[11,   150] loss: 0.5875078\n",
      "[12,   150] loss: 0.5764148\n",
      "[13,   150] loss: 0.5630398\n",
      "[14,   150] loss: 0.5481285\n",
      "[15,   150] loss: 0.5305133\n",
      "[16,   150] loss: 0.5115391\n",
      "[17,   150] loss: 0.4930430\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-10731d45e7de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    230\u001b[0m         \"\"\"\n\u001b[0;32m    231\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    902\u001b[0m         \"\"\"\n\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"P\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                             \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader1, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer1.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cnn1(inputs)\n",
    "        cnn_loss = cnn_criterion(outputs, labels)\n",
    "        cnn_loss.backward()\n",
    "        optimizer1.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += cnn_loss.item()\n",
    "        \n",
    "    print('[%d, %5d] loss: %.7f' %(epoch, num_epochs, running_loss/len(train_loader1)))\n",
    "    \n",
    "print('Finished Training')\n",
    "    \n",
    "with torch.no_grad():\n",
    "    error = 0\n",
    "    total = 0\n",
    "    for data in test_loader1:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network \n",
    "        outputs = cnn1(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        error += (predicted != labels).sum().item()\n",
    "\n",
    "cnn_err_rate.append(error/total)\n",
    "print('Error rate of test images: %f' % (error / total))\n",
    "\n",
    "\n",
    "ae_err = 0\n",
    "for i, (X_abnormal, _) in enumerate(abnormal_loader1):\n",
    "    output = AE(X_abnormal)\n",
    "    ae_loss = ae_criterion(X_abnormal, output)\n",
    "        \n",
    "    if ae_loss.item() < threshold:\n",
    "        ae_err += 1\n",
    "    \n",
    "ae_err_rate.append(ae_err)\n",
    "print('AE error rate : %.6f ' %(ae_err/len(abnormal_loader1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c0960",
   "metadata": {},
   "source": [
    "***train(30)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de8cef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader2, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer2.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cnn2(inputs)\n",
    "        cnn_loss = cnn_criterion(outputs, labels)\n",
    "        cnn_loss.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += cnn_loss.item()\n",
    "        \n",
    "    print('[%d, %5d] loss: %.7f' %(epoch, num_epochs, running_loss/len(train_loader2)))\n",
    "    \n",
    "print('Finished Training')\n",
    "    \n",
    "with torch.no_grad():\n",
    "    error = 0\n",
    "    total = 0\n",
    "    for data in test_loader2:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network \n",
    "        outputs = cnn2(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        error += (predicted != labels).sum().item()\n",
    "\n",
    "cnn_err_rate.append(error/total)\n",
    "print('Error rate of test images: %f' % (error / total))\n",
    "\n",
    "\n",
    "ae_err = 0\n",
    "for i, (X_abnormal, _) in enumerate(abnormal_loader2):\n",
    "    output = AE(X_abnormal)\n",
    "    ae_loss = ae_criterion(X_abnormal, output)\n",
    "        \n",
    "    if ae_loss.item() < threshold:\n",
    "        ae_err += 1\n",
    "    \n",
    "ae_err_rate.append(ae_err)\n",
    "print('AE error rate : %.6f ' %(ae_err/len(abnormal_loader1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93757d63",
   "metadata": {},
   "source": [
    "***train(60)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c175de71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,   150] loss: 0.6935536\n",
      "[1,   150] loss: 0.6934143\n",
      "[2,   150] loss: 0.6932765\n",
      "[3,   150] loss: 0.6931728\n",
      "[4,   150] loss: 0.6930068\n",
      "[5,   150] loss: 0.6928906\n",
      "[6,   150] loss: 0.6927935\n",
      "[7,   150] loss: 0.6926973\n",
      "[8,   150] loss: 0.6926138\n",
      "[9,   150] loss: 0.6925213\n",
      "[10,   150] loss: 0.6924452\n",
      "[11,   150] loss: 0.6923357\n",
      "[12,   150] loss: 0.6922630\n",
      "[13,   150] loss: 0.6921872\n",
      "[14,   150] loss: 0.6921197\n",
      "[15,   150] loss: 0.6920380\n",
      "[16,   150] loss: 0.6919820\n",
      "[17,   150] loss: 0.6919225\n",
      "[18,   150] loss: 0.6918564\n",
      "[19,   150] loss: 0.6917981\n",
      "[20,   150] loss: 0.6917432\n",
      "[21,   150] loss: 0.6916738\n",
      "[22,   150] loss: 0.6916324\n",
      "[23,   150] loss: 0.6915662\n",
      "[24,   150] loss: 0.6915264\n",
      "[25,   150] loss: 0.6914637\n",
      "[26,   150] loss: 0.6914225\n",
      "[27,   150] loss: 0.6913690\n",
      "[28,   150] loss: 0.6913245\n",
      "[29,   150] loss: 0.6912726\n",
      "[30,   150] loss: 0.6912335\n",
      "[31,   150] loss: 0.6911887\n",
      "[32,   150] loss: 0.6911374\n",
      "[33,   150] loss: 0.6910996\n",
      "[34,   150] loss: 0.6910605\n",
      "[35,   150] loss: 0.6910055\n",
      "[36,   150] loss: 0.6909741\n",
      "[37,   150] loss: 0.6909311\n",
      "[38,   150] loss: 0.6908841\n",
      "[39,   150] loss: 0.6908460\n",
      "[40,   150] loss: 0.6907997\n",
      "[41,   150] loss: 0.6907724\n",
      "[42,   150] loss: 0.6907239\n",
      "[43,   150] loss: 0.6906791\n",
      "[44,   150] loss: 0.6906520\n",
      "[45,   150] loss: 0.6906002\n",
      "[46,   150] loss: 0.6905685\n",
      "[47,   150] loss: 0.6905268\n",
      "[48,   150] loss: 0.6904869\n",
      "[49,   150] loss: 0.6904489\n",
      "[50,   150] loss: 0.6904035\n",
      "[51,   150] loss: 0.6903772\n",
      "[52,   150] loss: 0.6903349\n",
      "[53,   150] loss: 0.6902556\n",
      "[54,   150] loss: 0.6902222\n",
      "[55,   150] loss: 0.6901555\n",
      "[56,   150] loss: 0.6901176\n",
      "[57,   150] loss: 0.6900639\n",
      "[58,   150] loss: 0.6900178\n",
      "[59,   150] loss: 0.6899715\n",
      "[60,   150] loss: 0.6899301\n",
      "[61,   150] loss: 0.6898509\n",
      "[62,   150] loss: 0.6898297\n",
      "[63,   150] loss: 0.6897730\n",
      "[64,   150] loss: 0.6897117\n",
      "[65,   150] loss: 0.6896744\n",
      "[66,   150] loss: 0.6896194\n",
      "[67,   150] loss: 0.6895584\n",
      "[68,   150] loss: 0.6895017\n",
      "[69,   150] loss: 0.6894480\n",
      "[70,   150] loss: 0.6893760\n",
      "[71,   150] loss: 0.6893350\n",
      "[72,   150] loss: 0.6892698\n",
      "[73,   150] loss: 0.6892120\n",
      "[74,   150] loss: 0.6891512\n",
      "[75,   150] loss: 0.6890829\n",
      "[76,   150] loss: 0.6890143\n",
      "[77,   150] loss: 0.6889477\n",
      "[78,   150] loss: 0.6888868\n",
      "[79,   150] loss: 0.6888139\n",
      "[80,   150] loss: 0.6887362\n",
      "[81,   150] loss: 0.6886648\n",
      "[82,   150] loss: 0.6885875\n",
      "[83,   150] loss: 0.6885145\n",
      "[84,   150] loss: 0.6884403\n",
      "[85,   150] loss: 0.6883518\n",
      "[86,   150] loss: 0.6882715\n",
      "[87,   150] loss: 0.6881855\n",
      "[88,   150] loss: 0.6880877\n",
      "[89,   150] loss: 0.6880084\n",
      "[90,   150] loss: 0.6879163\n",
      "[91,   150] loss: 0.6878037\n",
      "[92,   150] loss: 0.6877230\n",
      "[93,   150] loss: 0.6876130\n",
      "[94,   150] loss: 0.6875173\n",
      "[95,   150] loss: 0.6874010\n",
      "[96,   150] loss: 0.6872991\n",
      "[97,   150] loss: 0.6871674\n",
      "[98,   150] loss: 0.6870531\n",
      "[99,   150] loss: 0.6869268\n",
      "[100,   150] loss: 0.6868203\n",
      "[101,   150] loss: 0.6866891\n",
      "[102,   150] loss: 0.6865514\n",
      "[103,   150] loss: 0.6864090\n",
      "[104,   150] loss: 0.6862398\n",
      "[105,   150] loss: 0.6861228\n",
      "[106,   150] loss: 0.6859601\n",
      "[107,   150] loss: 0.6858069\n",
      "[108,   150] loss: 0.6856226\n",
      "[109,   150] loss: 0.6854854\n",
      "[110,   150] loss: 0.6852983\n",
      "[111,   150] loss: 0.6851479\n",
      "[112,   150] loss: 0.6849309\n",
      "[113,   150] loss: 0.6847151\n",
      "[114,   150] loss: 0.6844981\n",
      "[115,   150] loss: 0.6843076\n",
      "[116,   150] loss: 0.6840406\n",
      "[117,   150] loss: 0.6838171\n",
      "[118,   150] loss: 0.6835532\n",
      "[119,   150] loss: 0.6833068\n",
      "[120,   150] loss: 0.6830099\n",
      "[121,   150] loss: 0.6827312\n",
      "[122,   150] loss: 0.6824579\n",
      "[123,   150] loss: 0.6821347\n",
      "[124,   150] loss: 0.6817927\n",
      "[125,   150] loss: 0.6815231\n",
      "[126,   150] loss: 0.6810389\n",
      "[127,   150] loss: 0.6804192\n",
      "[128,   150] loss: 0.6799231\n",
      "[129,   150] loss: 0.6793776\n",
      "[130,   150] loss: 0.6789300\n",
      "[131,   150] loss: 0.6782815\n",
      "[132,   150] loss: 0.6778124\n",
      "[133,   150] loss: 0.6771836\n",
      "[134,   150] loss: 0.6765571\n",
      "[135,   150] loss: 0.6758765\n",
      "[136,   150] loss: 0.6750364\n",
      "[137,   150] loss: 0.6742713\n",
      "[138,   150] loss: 0.6734779\n",
      "[139,   150] loss: 0.6726321\n",
      "[140,   150] loss: 0.6716316\n",
      "[141,   150] loss: 0.6706761\n",
      "[142,   150] loss: 0.6695245\n",
      "[143,   150] loss: 0.6684966\n",
      "[144,   150] loss: 0.6671985\n",
      "[145,   150] loss: 0.6658412\n",
      "[146,   150] loss: 0.6643515\n",
      "[147,   150] loss: 0.6625108\n",
      "[148,   150] loss: 0.6607450\n",
      "[149,   150] loss: 0.6585253\n",
      "Finished Training\n",
      "Error rate of test images: 0.454545\n",
      "AE error rate : 0.000000 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader3, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer3.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cnn3(inputs)\n",
    "        cnn_loss = cnn_criterion(outputs, labels)\n",
    "        cnn_loss.backward()\n",
    "        optimizer3.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += cnn_loss.item()\n",
    "        \n",
    "    print('[%d, %5d] loss: %.7f' %(epoch, num_epochs, running_loss/len(train_loader3)))\n",
    "    \n",
    "print('Finished Training')\n",
    "    \n",
    "with torch.no_grad():\n",
    "    error = 0\n",
    "    total = 0\n",
    "    for data in test_loader3:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network \n",
    "        outputs = cnn3(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        error += (predicted != labels).sum().item()\n",
    "\n",
    "cnn_err_rate.append(error/total)\n",
    "print('Error rate of test images: %f' % (error / total))\n",
    "\n",
    "\n",
    "ae_err = 0\n",
    "for i, (X_abnormal, _) in enumerate(abnormal_loader3):\n",
    "    output = AE(X_abnormal)\n",
    "    ae_loss = ae_criterion(X_abnormal, output)\n",
    "        \n",
    "    if ae_loss.item() < threshold:\n",
    "        ae_err += 1\n",
    "    \n",
    "ae_err_rate.append(ae_err)\n",
    "print('AE error rate : %.6f ' %(ae_err/len(abnormal_loader3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77059cf",
   "metadata": {},
   "source": [
    "***train(90)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3089693",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,   150] loss: 0.6818708\n",
      "[1,   150] loss: 0.6804820\n",
      "[2,   150] loss: 0.6792663\n",
      "[3,   150] loss: 0.6782551\n",
      "[4,   150] loss: 0.6773681\n",
      "[5,   150] loss: 0.6765243\n",
      "[6,   150] loss: 0.6757328\n",
      "[7,   150] loss: 0.6749411\n",
      "[8,   150] loss: 0.6742388\n",
      "[9,   150] loss: 0.6735628\n",
      "[10,   150] loss: 0.6729397\n",
      "[11,   150] loss: 0.6723449\n",
      "[12,   150] loss: 0.6718229\n",
      "[13,   150] loss: 0.6712551\n",
      "[14,   150] loss: 0.6707301\n",
      "[15,   150] loss: 0.6702611\n",
      "[16,   150] loss: 0.6698222\n",
      "[17,   150] loss: 0.6694005\n",
      "[18,   150] loss: 0.6689832\n",
      "[19,   150] loss: 0.6686086\n",
      "[20,   150] loss: 0.6682348\n",
      "[21,   150] loss: 0.6679173\n",
      "[22,   150] loss: 0.6675731\n",
      "[23,   150] loss: 0.6672694\n",
      "[24,   150] loss: 0.6669828\n",
      "[25,   150] loss: 0.6666747\n",
      "[26,   150] loss: 0.6664305\n",
      "[27,   150] loss: 0.6661339\n",
      "[28,   150] loss: 0.6659105\n",
      "[29,   150] loss: 0.6657278\n",
      "[30,   150] loss: 0.6655171\n",
      "[31,   150] loss: 0.6652794\n",
      "[32,   150] loss: 0.6651312\n",
      "[33,   150] loss: 0.6649327\n",
      "[34,   150] loss: 0.6646882\n",
      "[35,   150] loss: 0.6645878\n",
      "[36,   150] loss: 0.6644975\n",
      "[37,   150] loss: 0.6642470\n",
      "[38,   150] loss: 0.6641839\n",
      "[39,   150] loss: 0.6640601\n",
      "[40,   150] loss: 0.6639347\n",
      "[41,   150] loss: 0.6638607\n",
      "[42,   150] loss: 0.6637307\n",
      "[43,   150] loss: 0.6636519\n",
      "[44,   150] loss: 0.6635547\n",
      "[45,   150] loss: 0.6635591\n",
      "[46,   150] loss: 0.6633289\n",
      "[47,   150] loss: 0.6633699\n",
      "[48,   150] loss: 0.6631462\n",
      "[49,   150] loss: 0.6632156\n",
      "[50,   150] loss: 0.6630684\n",
      "[51,   150] loss: 0.6630121\n",
      "[52,   150] loss: 0.6629819\n",
      "[53,   150] loss: 0.6629546\n",
      "[54,   150] loss: 0.6629195\n",
      "[55,   150] loss: 0.6628095\n",
      "[56,   150] loss: 0.6628146\n",
      "[57,   150] loss: 0.6627294\n",
      "[58,   150] loss: 0.6627103\n",
      "[59,   150] loss: 0.6627289\n",
      "[60,   150] loss: 0.6625449\n",
      "[61,   150] loss: 0.6626237\n",
      "[62,   150] loss: 0.6625645\n",
      "[63,   150] loss: 0.6624931\n",
      "[64,   150] loss: 0.6624646\n",
      "[65,   150] loss: 0.6624694\n",
      "[66,   150] loss: 0.6624078\n",
      "[67,   150] loss: 0.6624079\n",
      "[68,   150] loss: 0.6623664\n",
      "[69,   150] loss: 0.6623429\n",
      "[70,   150] loss: 0.6623139\n",
      "[71,   150] loss: 0.6622561\n",
      "[72,   150] loss: 0.6622317\n",
      "[73,   150] loss: 0.6622002\n",
      "[74,   150] loss: 0.6621544\n",
      "[75,   150] loss: 0.6621947\n",
      "[76,   150] loss: 0.6621391\n",
      "[77,   150] loss: 0.6620668\n",
      "[78,   150] loss: 0.6621184\n",
      "[79,   150] loss: 0.6620199\n",
      "[80,   150] loss: 0.6620253\n",
      "[81,   150] loss: 0.6619761\n",
      "[82,   150] loss: 0.6619851\n",
      "[83,   150] loss: 0.6619669\n",
      "[84,   150] loss: 0.6618862\n",
      "[85,   150] loss: 0.6618550\n",
      "[86,   150] loss: 0.6618690\n",
      "[87,   150] loss: 0.6618037\n",
      "[88,   150] loss: 0.6618038\n",
      "[89,   150] loss: 0.6617592\n",
      "[90,   150] loss: 0.6617076\n",
      "[91,   150] loss: 0.6617213\n",
      "[92,   150] loss: 0.6616857\n",
      "[93,   150] loss: 0.6616887\n",
      "[94,   150] loss: 0.6615758\n",
      "[95,   150] loss: 0.6616124\n",
      "[96,   150] loss: 0.6615597\n",
      "[97,   150] loss: 0.6615278\n",
      "[98,   150] loss: 0.6615004\n",
      "[99,   150] loss: 0.6614441\n",
      "[100,   150] loss: 0.6614563\n",
      "[101,   150] loss: 0.6614245\n",
      "[102,   150] loss: 0.6613477\n",
      "[103,   150] loss: 0.6612309\n",
      "[104,   150] loss: 0.6610688\n",
      "[105,   150] loss: 0.6612833\n",
      "[106,   150] loss: 0.6613416\n",
      "[107,   150] loss: 0.6612008\n",
      "[108,   150] loss: 0.6610876\n",
      "[109,   150] loss: 0.6611487\n",
      "[110,   150] loss: 0.6610078\n",
      "[111,   150] loss: 0.6610407\n",
      "[112,   150] loss: 0.6608559\n",
      "[113,   150] loss: 0.6609659\n",
      "[114,   150] loss: 0.6605714\n",
      "[115,   150] loss: 0.6610312\n",
      "[116,   150] loss: 0.6607421\n",
      "[117,   150] loss: 0.6604534\n",
      "[118,   150] loss: 0.6608882\n",
      "[119,   150] loss: 0.6606554\n",
      "[120,   150] loss: 0.6606504\n",
      "[121,   150] loss: 0.6604829\n",
      "[122,   150] loss: 0.6608002\n",
      "[123,   150] loss: 0.6599828\n",
      "[124,   150] loss: 0.6606980\n",
      "[125,   150] loss: 0.6598395\n",
      "[126,   150] loss: 0.6601844\n",
      "[127,   150] loss: 0.6603586\n",
      "[128,   150] loss: 0.6598874\n",
      "[129,   150] loss: 0.6603285\n",
      "[130,   150] loss: 0.6594341\n",
      "[131,   150] loss: 0.6598927\n",
      "[132,   150] loss: 0.6595570\n",
      "[133,   150] loss: 0.6597498\n",
      "[134,   150] loss: 0.6594361\n",
      "[135,   150] loss: 0.6594005\n",
      "[136,   150] loss: 0.6594036\n",
      "[137,   150] loss: 0.6592461\n",
      "[138,   150] loss: 0.6593169\n",
      "[139,   150] loss: 0.6588982\n",
      "[140,   150] loss: 0.6587529\n",
      "[141,   150] loss: 0.6587268\n",
      "[142,   150] loss: 0.6586551\n",
      "[143,   150] loss: 0.6584895\n",
      "[144,   150] loss: 0.6583795\n",
      "[145,   150] loss: 0.6582371\n",
      "[146,   150] loss: 0.6580516\n",
      "[147,   150] loss: 0.6579069\n",
      "[148,   150] loss: 0.6576770\n",
      "[149,   150] loss: 0.6574321\n",
      "Finished Training\n",
      "Error rate of test images: 0.357143\n",
      "AE error rate : 0.000000 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader4, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer4.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cnn4(inputs)\n",
    "        cnn_loss = cnn_criterion(outputs, labels)\n",
    "        cnn_loss.backward()\n",
    "        optimizer4.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += cnn_loss.item()\n",
    "        \n",
    "    print('[%d, %5d] loss: %.7f' %(epoch, num_epochs, running_loss/len(train_loader4)))\n",
    "    \n",
    "print('Finished Training')\n",
    "    \n",
    "with torch.no_grad():\n",
    "    error = 0\n",
    "    total = 0\n",
    "    for data in test_loader4:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network \n",
    "        outputs = cnn4(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        error += (predicted != labels).sum().item()\n",
    "\n",
    "cnn_err_rate.append(error/total)\n",
    "print('Error rate of test images: %f' % (error / total))\n",
    "\n",
    "\n",
    "ae_err = 0\n",
    "for i, (X_abnormal, _) in enumerate(abnormal_loader4):\n",
    "    output = AE(X_abnormal)\n",
    "    ae_loss = ae_criterion(X_abnormal, output)\n",
    "        \n",
    "    if ae_loss.item() < threshold:\n",
    "        ae_err += 1\n",
    "    \n",
    "ae_err_rate.append(ae_err)\n",
    "print('AE error rate : %.6f ' %(ae_err/len(abnormal_loader4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b14690",
   "metadata": {},
   "source": [
    "***train(120)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec427633",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,   150] loss: 0.7211619\n",
      "[1,   150] loss: 0.7115966\n",
      "[2,   150] loss: 0.7020277\n",
      "[3,   150] loss: 0.6928392\n",
      "[4,   150] loss: 0.6846283\n",
      "[5,   150] loss: 0.6762189\n",
      "[6,   150] loss: 0.6683420\n",
      "[7,   150] loss: 0.6609140\n",
      "[8,   150] loss: 0.6536231\n",
      "[9,   150] loss: 0.6478960\n",
      "[10,   150] loss: 0.6423393\n",
      "[11,   150] loss: 0.6393054\n",
      "[12,   150] loss: 0.6363997\n",
      "[13,   150] loss: 0.6352700\n",
      "[14,   150] loss: 0.6346193\n",
      "[15,   150] loss: 0.6336602\n",
      "[16,   150] loss: 0.6338269\n",
      "[17,   150] loss: 0.6333980\n",
      "[18,   150] loss: 0.6331753\n",
      "[19,   150] loss: 0.6329311\n",
      "[20,   150] loss: 0.6327039\n",
      "[21,   150] loss: 0.6326296\n",
      "[22,   150] loss: 0.6324134\n",
      "[23,   150] loss: 0.6321733\n",
      "[24,   150] loss: 0.6320450\n",
      "[25,   150] loss: 0.6319112\n",
      "[26,   150] loss: 0.6317691\n",
      "[27,   150] loss: 0.6316313\n",
      "[28,   150] loss: 0.6314233\n",
      "[29,   150] loss: 0.6311982\n",
      "[30,   150] loss: 0.6311921\n",
      "[31,   150] loss: 0.6308949\n",
      "[32,   150] loss: 0.6308220\n",
      "[33,   150] loss: 0.6306032\n",
      "[34,   150] loss: 0.6305029\n",
      "[35,   150] loss: 0.6303345\n",
      "[36,   150] loss: 0.6301069\n",
      "[37,   150] loss: 0.6298325\n",
      "[38,   150] loss: 0.6299624\n",
      "[39,   150] loss: 0.6295040\n",
      "[40,   150] loss: 0.6295056\n",
      "[41,   150] loss: 0.6291108\n",
      "[42,   150] loss: 0.6289835\n",
      "[43,   150] loss: 0.6288375\n",
      "[44,   150] loss: 0.6287215\n",
      "[45,   150] loss: 0.6284213\n",
      "[46,   150] loss: 0.6282004\n",
      "[47,   150] loss: 0.6276306\n",
      "[48,   150] loss: 0.6275603\n",
      "[49,   150] loss: 0.6274618\n",
      "[50,   150] loss: 0.6272048\n",
      "[51,   150] loss: 0.6270426\n",
      "[52,   150] loss: 0.6267619\n",
      "[53,   150] loss: 0.6264329\n",
      "[54,   150] loss: 0.6261907\n",
      "[55,   150] loss: 0.6258816\n",
      "[56,   150] loss: 0.6254321\n",
      "[57,   150] loss: 0.6252771\n",
      "[58,   150] loss: 0.6248590\n",
      "[59,   150] loss: 0.6244937\n",
      "[60,   150] loss: 0.6241468\n",
      "[61,   150] loss: 0.6237521\n",
      "[62,   150] loss: 0.6233244\n",
      "[63,   150] loss: 0.6228385\n",
      "[64,   150] loss: 0.6221726\n",
      "[65,   150] loss: 0.6222349\n",
      "[66,   150] loss: 0.6211348\n",
      "[67,   150] loss: 0.6204753\n",
      "[68,   150] loss: 0.6198755\n",
      "[69,   150] loss: 0.6190210\n",
      "[70,   150] loss: 0.6182536\n",
      "[71,   150] loss: 0.6176158\n",
      "[72,   150] loss: 0.6163466\n",
      "[73,   150] loss: 0.6160452\n",
      "[74,   150] loss: 0.6147243\n",
      "[75,   150] loss: 0.6134867\n",
      "[76,   150] loss: 0.6124902\n",
      "[77,   150] loss: 0.6112457\n",
      "[78,   150] loss: 0.6102207\n",
      "[79,   150] loss: 0.6084292\n",
      "[80,   150] loss: 0.6070431\n",
      "[81,   150] loss: 0.6041377\n",
      "[82,   150] loss: 0.6024844\n",
      "[83,   150] loss: 0.6005907\n",
      "[84,   150] loss: 0.5978503\n",
      "[85,   150] loss: 0.5945568\n",
      "[86,   150] loss: 0.5911917\n",
      "[87,   150] loss: 0.5867711\n",
      "[88,   150] loss: 0.5818598\n",
      "[89,   150] loss: 0.5763588\n",
      "[90,   150] loss: 0.5688673\n",
      "[91,   150] loss: 0.5605159\n",
      "[92,   150] loss: 0.5495922\n",
      "[93,   150] loss: 0.5369108\n",
      "[94,   150] loss: 0.5179833\n",
      "[95,   150] loss: 0.4954749\n",
      "[96,   150] loss: 0.4722488\n",
      "[97,   150] loss: 0.4471082\n",
      "[98,   150] loss: 0.4163156\n",
      "[99,   150] loss: 0.3888632\n",
      "[100,   150] loss: 0.3589087\n",
      "[101,   150] loss: 0.3273286\n",
      "[102,   150] loss: 0.2962047\n",
      "[103,   150] loss: 0.2660716\n",
      "[104,   150] loss: 0.2375189\n",
      "[105,   150] loss: 0.2140666\n",
      "[106,   150] loss: 0.1899273\n",
      "[107,   150] loss: 0.1683662\n",
      "[108,   150] loss: 0.1486384\n",
      "[109,   150] loss: 0.1297162\n",
      "[110,   150] loss: 0.1107414\n",
      "[111,   150] loss: 0.0941148\n",
      "[112,   150] loss: 0.0790115\n",
      "[113,   150] loss: 0.0645438\n",
      "[114,   150] loss: 0.0529905\n",
      "[115,   150] loss: 0.0432481\n",
      "[116,   150] loss: 0.0360753\n",
      "[117,   150] loss: 0.0303811\n",
      "[118,   150] loss: 0.0261406\n",
      "[119,   150] loss: 0.0229343\n",
      "[120,   150] loss: 0.0203943\n",
      "[121,   150] loss: 0.0182367\n",
      "[122,   150] loss: 0.0164108\n",
      "[123,   150] loss: 0.0147942\n",
      "[124,   150] loss: 0.0133987\n",
      "[125,   150] loss: 0.0121835\n",
      "[126,   150] loss: 0.0111184\n",
      "[127,   150] loss: 0.0101831\n",
      "[128,   150] loss: 0.0093476\n",
      "[129,   150] loss: 0.0086136\n",
      "[130,   150] loss: 0.0079607\n",
      "[131,   150] loss: 0.0073820\n",
      "[132,   150] loss: 0.0068703\n",
      "[133,   150] loss: 0.0064129\n",
      "[134,   150] loss: 0.0059974\n",
      "[135,   150] loss: 0.0056177\n",
      "[136,   150] loss: 0.0052667\n",
      "[137,   150] loss: 0.0049401\n",
      "[138,   150] loss: 0.0046369\n",
      "[139,   150] loss: 0.0043602\n",
      "[140,   150] loss: 0.0041076\n",
      "[141,   150] loss: 0.0038744\n",
      "[142,   150] loss: 0.0036599\n",
      "[143,   150] loss: 0.0034623\n",
      "[144,   150] loss: 0.0032802\n",
      "[145,   150] loss: 0.0031117\n",
      "[146,   150] loss: 0.0029556\n",
      "[147,   150] loss: 0.0028103\n",
      "[148,   150] loss: 0.0026754\n",
      "[149,   150] loss: 0.0025500\n",
      "Finished Training\n",
      "Error rate of test images: 0.000000\n",
      "AE error rate : 0.000000 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader5, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer5.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cnn5(inputs)\n",
    "        cnn_loss = cnn_criterion(outputs, labels)\n",
    "        cnn_loss.backward()\n",
    "        optimizer5.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += cnn_loss.item()\n",
    "        \n",
    "    print('[%d, %5d] loss: %.7f' %(epoch, num_epochs, running_loss/len(train_loader5)))\n",
    "    \n",
    "print('Finished Training')\n",
    "    \n",
    "with torch.no_grad():\n",
    "    error = 0\n",
    "    total = 0\n",
    "    for data in test_loader5:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network \n",
    "        outputs = cnn5(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        error += (predicted != labels).sum().item()\n",
    "\n",
    "cnn_err_rate.append(error/total)\n",
    "print('Error rate of test images: %f' % (error / total))\n",
    "\n",
    "\n",
    "ae_err = 0\n",
    "for i, (X_abnormal, _) in enumerate(abnormal_loader5):\n",
    "    output = AE(X_abnormal)\n",
    "    ae_loss = ae_criterion(X_abnormal, output)\n",
    "        \n",
    "    if ae_loss.item() < threshold:\n",
    "        ae_err += 1\n",
    "    \n",
    "ae_err_rate.append(ae_err)\n",
    "print('AE error rate : %.6f ' %(ae_err/len(abnormal_loader5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b722440",
   "metadata": {},
   "source": [
    "***train(180)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48e25b27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,   150] loss: 0.6646744\n",
      "[1,   150] loss: 0.6564943\n",
      "[2,   150] loss: 0.6491924\n",
      "[3,   150] loss: 0.6426570\n",
      "[4,   150] loss: 0.6365631\n",
      "[5,   150] loss: 0.6307472\n",
      "[6,   150] loss: 0.6251794\n",
      "[7,   150] loss: 0.6197969\n",
      "[8,   150] loss: 0.6143075\n",
      "[9,   150] loss: 0.6095438\n",
      "[10,   150] loss: 0.6048578\n",
      "[11,   150] loss: 0.6005110\n",
      "[12,   150] loss: 0.5965437\n",
      "[13,   150] loss: 0.5921256\n",
      "[14,   150] loss: 0.5879738\n",
      "[15,   150] loss: 0.5841842\n",
      "[16,   150] loss: 0.5806844\n",
      "[17,   150] loss: 0.5772655\n",
      "[18,   150] loss: 0.5742916\n",
      "[19,   150] loss: 0.5720409\n",
      "[20,   150] loss: 0.5702171\n",
      "[21,   150] loss: 0.5690709\n",
      "[22,   150] loss: 0.5682594\n",
      "[23,   150] loss: 0.5677019\n",
      "[24,   150] loss: 0.5673763\n",
      "[25,   150] loss: 0.5670232\n",
      "[26,   150] loss: 0.5667540\n",
      "[27,   150] loss: 0.5666239\n",
      "[28,   150] loss: 0.5664785\n",
      "[29,   150] loss: 0.5663482\n",
      "[30,   150] loss: 0.5662532\n",
      "[31,   150] loss: 0.5660936\n",
      "[32,   150] loss: 0.5659882\n",
      "[33,   150] loss: 0.5659697\n",
      "[34,   150] loss: 0.5658416\n",
      "[35,   150] loss: 0.5658044\n",
      "[36,   150] loss: 0.5656771\n",
      "[37,   150] loss: 0.5656187\n",
      "[38,   150] loss: 0.5655309\n",
      "[39,   150] loss: 0.5654154\n",
      "[40,   150] loss: 0.5653273\n",
      "[41,   150] loss: 0.5652412\n",
      "[42,   150] loss: 0.5651340\n",
      "[43,   150] loss: 0.5650563\n",
      "[44,   150] loss: 0.5649640\n",
      "[45,   150] loss: 0.5648551\n",
      "[46,   150] loss: 0.5647742\n",
      "[47,   150] loss: 0.5646575\n",
      "[48,   150] loss: 0.5645740\n",
      "[49,   150] loss: 0.5644771\n",
      "[50,   150] loss: 0.5643708\n",
      "[51,   150] loss: 0.5642718\n",
      "[52,   150] loss: 0.5641566\n",
      "[53,   150] loss: 0.5640049\n",
      "[54,   150] loss: 0.5639436\n",
      "[55,   150] loss: 0.5638486\n",
      "[56,   150] loss: 0.5636513\n",
      "[57,   150] loss: 0.5637797\n",
      "[58,   150] loss: 0.5635232\n",
      "[59,   150] loss: 0.5632673\n",
      "[60,   150] loss: 0.5634739\n",
      "[61,   150] loss: 0.5630178\n",
      "[62,   150] loss: 0.5632482\n",
      "[63,   150] loss: 0.5626995\n",
      "[64,   150] loss: 0.5628392\n",
      "[65,   150] loss: 0.5627022\n",
      "[66,   150] loss: 0.5625530\n",
      "[67,   150] loss: 0.5621903\n",
      "[68,   150] loss: 0.5622218\n",
      "[69,   150] loss: 0.5621184\n",
      "[70,   150] loss: 0.5620218\n",
      "[71,   150] loss: 0.5618420\n",
      "[72,   150] loss: 0.5612232\n",
      "[73,   150] loss: 0.5616478\n",
      "[74,   150] loss: 0.5614188\n",
      "[75,   150] loss: 0.5612368\n",
      "[76,   150] loss: 0.5602245\n",
      "[77,   150] loss: 0.5607948\n",
      "[78,   150] loss: 0.5607078\n",
      "[79,   150] loss: 0.5603651\n",
      "[80,   150] loss: 0.5601669\n",
      "[81,   150] loss: 0.5598886\n",
      "[82,   150] loss: 0.5596352\n",
      "[83,   150] loss: 0.5594480\n",
      "[84,   150] loss: 0.5591044\n",
      "[85,   150] loss: 0.5589081\n",
      "[86,   150] loss: 0.5585379\n",
      "[87,   150] loss: 0.5582646\n",
      "[88,   150] loss: 0.5576937\n",
      "[89,   150] loss: 0.5574494\n",
      "[90,   150] loss: 0.5570983\n",
      "[91,   150] loss: 0.5566563\n",
      "[92,   150] loss: 0.5562532\n",
      "[93,   150] loss: 0.5560481\n",
      "[94,   150] loss: 0.5554132\n",
      "[95,   150] loss: 0.5550919\n",
      "[96,   150] loss: 0.5544547\n",
      "[97,   150] loss: 0.5537663\n",
      "[98,   150] loss: 0.5533450\n",
      "[99,   150] loss: 0.5527826\n",
      "[100,   150] loss: 0.5519876\n",
      "[101,   150] loss: 0.5512219\n",
      "[102,   150] loss: 0.5505510\n",
      "[103,   150] loss: 0.5496835\n",
      "[104,   150] loss: 0.5487662\n",
      "[105,   150] loss: 0.5477379\n",
      "[106,   150] loss: 0.5464196\n",
      "[107,   150] loss: 0.5452809\n",
      "[108,   150] loss: 0.5438951\n",
      "[109,   150] loss: 0.5422128\n",
      "[110,   150] loss: 0.5406725\n",
      "[111,   150] loss: 0.5392821\n",
      "[112,   150] loss: 0.5370878\n",
      "[113,   150] loss: 0.5348389\n",
      "[114,   150] loss: 0.5322493\n",
      "[115,   150] loss: 0.5272635\n",
      "[116,   150] loss: 0.5240705\n",
      "[117,   150] loss: 0.5203189\n",
      "[118,   150] loss: 0.5156032\n",
      "[119,   150] loss: 0.5069721\n",
      "[120,   150] loss: 0.5018830\n",
      "[121,   150] loss: 0.4914045\n",
      "[122,   150] loss: 0.4825106\n",
      "[123,   150] loss: 0.4730155\n",
      "[124,   150] loss: 0.4630165\n",
      "[125,   150] loss: 0.4505266\n",
      "[126,   150] loss: 0.4348159\n",
      "[127,   150] loss: 0.4212694\n",
      "[128,   150] loss: 0.4079105\n",
      "[129,   150] loss: 0.3942404\n",
      "[130,   150] loss: 0.3751971\n",
      "[131,   150] loss: 0.3562708\n",
      "[132,   150] loss: 0.3326477\n",
      "[133,   150] loss: 0.3067721\n",
      "[134,   150] loss: 0.2824272\n",
      "[135,   150] loss: 0.2600532\n",
      "[136,   150] loss: 0.2419717\n",
      "[137,   150] loss: 0.2263148\n",
      "[138,   150] loss: 0.2102704\n",
      "[139,   150] loss: 0.1986662\n",
      "[140,   150] loss: 0.1850837\n",
      "[141,   150] loss: 0.1706378\n",
      "[142,   150] loss: 0.1577599\n",
      "[143,   150] loss: 0.1445519\n",
      "[144,   150] loss: 0.1309961\n",
      "[145,   150] loss: 0.1167188\n",
      "[146,   150] loss: 0.1026254\n",
      "[147,   150] loss: 0.0883184\n",
      "[148,   150] loss: 0.0743284\n",
      "[149,   150] loss: 0.0609426\n",
      "Finished Training\n",
      "Error rate of test images: 0.500000\n",
      "AE error rate : 0.000000 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader6, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer6.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cnn6(inputs)\n",
    "        cnn_loss = cnn_criterion(outputs, labels)\n",
    "        cnn_loss.backward()\n",
    "        optimizer6.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += cnn_loss.item()\n",
    "        \n",
    "    print('[%d, %5d] loss: %.7f' %(epoch, num_epochs, running_loss/len(train_loader6)))\n",
    "    \n",
    "print('Finished Training')\n",
    "    \n",
    "with torch.no_grad():\n",
    "    error = 0\n",
    "    total = 0\n",
    "    for data in test_loader6:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network \n",
    "        outputs = cnn6(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        error += (predicted != labels).sum().item()\n",
    "\n",
    "cnn_err_rate.append(error/total)\n",
    "print('Error rate of test images: %f' % (error / total))\n",
    "\n",
    "\n",
    "ae_err = 0\n",
    "for i, (X_abnormal, _) in enumerate(abnormal_loader6):\n",
    "    output = AE(X_abnormal)\n",
    "    ae_loss = ae_criterion(X_abnormal, output)\n",
    "        \n",
    "    if ae_loss.item() < threshold:\n",
    "        ae_err += 1\n",
    "    \n",
    "ae_err_rate.append(ae_err)\n",
    "print('AE error rate : %.6f ' %(ae_err/len(abnormal_loader6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7dc27b",
   "metadata": {},
   "source": [
    "***train(230)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc40985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,   150] loss: 0.6618015\n",
      "[1,   150] loss: 0.6434294\n",
      "[2,   150] loss: 0.6274805\n",
      "[3,   150] loss: 0.6126311\n",
      "[4,   150] loss: 0.5985668\n",
      "[5,   150] loss: 0.5851355\n",
      "[6,   150] loss: 0.5710666\n",
      "[7,   150] loss: 0.5555923\n",
      "[8,   150] loss: 0.5384108\n",
      "[9,   150] loss: 0.5186588\n",
      "[10,   150] loss: 0.4986891\n",
      "[11,   150] loss: 0.4855511\n",
      "[12,   150] loss: 0.4780114\n",
      "[13,   150] loss: 0.4756429\n",
      "[14,   150] loss: 0.4749390\n",
      "[15,   150] loss: 0.4747177\n",
      "[16,   150] loss: 0.4744659\n",
      "[17,   150] loss: 0.4742995\n",
      "[18,   150] loss: 0.4741461\n",
      "[19,   150] loss: 0.4740057\n",
      "[20,   150] loss: 0.4739233\n",
      "[21,   150] loss: 0.4737939\n",
      "[22,   150] loss: 0.4736884\n",
      "[23,   150] loss: 0.4736025\n",
      "[24,   150] loss: 0.4734974\n",
      "[25,   150] loss: 0.4733674\n",
      "[26,   150] loss: 0.4733151\n",
      "[27,   150] loss: 0.4732866\n",
      "[28,   150] loss: 0.4730146\n",
      "[29,   150] loss: 0.4729700\n",
      "[30,   150] loss: 0.4729085\n",
      "[31,   150] loss: 0.4724557\n",
      "[32,   150] loss: 0.4726816\n",
      "[33,   150] loss: 0.4725411\n",
      "[34,   150] loss: 0.4724897\n",
      "[35,   150] loss: 0.4722597\n",
      "[36,   150] loss: 0.4723226\n",
      "[37,   150] loss: 0.4720315\n",
      "[38,   150] loss: 0.4720303\n",
      "[39,   150] loss: 0.4718768\n",
      "[40,   150] loss: 0.4717889\n",
      "[41,   150] loss: 0.4717295\n",
      "[42,   150] loss: 0.4715726\n",
      "[43,   150] loss: 0.4714455\n",
      "[44,   150] loss: 0.4712992\n",
      "[45,   150] loss: 0.4712808\n",
      "[46,   150] loss: 0.4711074\n",
      "[47,   150] loss: 0.4710382\n",
      "[48,   150] loss: 0.4708663\n",
      "[49,   150] loss: 0.4707753\n",
      "[50,   150] loss: 0.4705173\n",
      "[51,   150] loss: 0.4704989\n",
      "[52,   150] loss: 0.4702715\n",
      "[53,   150] loss: 0.4701999\n",
      "[54,   150] loss: 0.4701099\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader7, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer7.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cnn7(inputs)\n",
    "        cnn_loss = cnn_criterion(outputs, labels)\n",
    "        cnn_loss.backward()\n",
    "        optimizer7.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += cnn_loss.item()\n",
    "        \n",
    "    print('[%d, %5d] loss: %.7f' %(epoch, num_epochs, running_loss/len(train_loader7)))\n",
    "    \n",
    "print('Finished Training')\n",
    "    \n",
    "with torch.no_grad():\n",
    "    error = 0\n",
    "    total = 0\n",
    "    for data in test_loader7:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network \n",
    "        outputs = cnn7(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        error += (predicted != labels).sum().item()\n",
    "\n",
    "cnn_err_rate.append(error/total)\n",
    "print('Error rate of test images: %f' % (error / total))\n",
    "\n",
    "\n",
    "ae_err = 0\n",
    "for i, (X_abnormal, _) in enumerate(abnormal_loader7):\n",
    "    output = AE(X_abnormal)\n",
    "    ae_loss = ae_criterion(X_abnormal, output)\n",
    "        \n",
    "    if ae_loss.item() < threshold:\n",
    "        ae_err += 1\n",
    "    \n",
    "ae_err_rate.append(ae_err)\n",
    "print('AE error rate : %.6f ' %(ae_err/len(abnormal_loader7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a9784",
   "metadata": {},
   "source": [
    "***train(300)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e8014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader8, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer8.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cnn8(inputs)\n",
    "        cnn_loss = cnn_criterion(outputs, labels)\n",
    "        cnn_loss.backward()\n",
    "        optimizer8.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += cnn_loss.item()\n",
    "        \n",
    "    print('[%d, %5d] loss: %.7f' %(epoch, num_epochs, running_loss/len(train_loader8)))\n",
    "    \n",
    "print('Finished Training')\n",
    "    \n",
    "with torch.no_grad():\n",
    "    error = 0\n",
    "    total = 0\n",
    "    for data in test_loader8:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network \n",
    "        outputs = cnn8(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        error += (predicted != labels).sum().item()\n",
    "\n",
    "cnn_err_rate.append(error/total)\n",
    "print('Error rate of test images: %f' % (error / total))\n",
    "\n",
    "\n",
    "ae_err = 0\n",
    "for i, (X_abnormal, _) in enumerate(abnormal_loader8):\n",
    "    output = AE(X_abnormal)\n",
    "    ae_loss = ae_criterion(X_abnormal, output)\n",
    "        \n",
    "    if ae_loss.item() < threshold:\n",
    "        ae_err += 1\n",
    "    \n",
    "ae_err_rate.append(ae_err)\n",
    "print('AE error rate : %.6f ' %(ae_err/len(abnormal_loader8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b13bfa7",
   "metadata": {},
   "source": [
    "***graph***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f8bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_abnormal = [10, 30, 60, 90, 120, 150, 230, 300]\n",
    "num_abnormal = [60, 90, 120, 150, 230, 300]\n",
    "\n",
    "plt.plot(num_abnormal, cnn_err_rate, label = 'CNN')\n",
    "plt.plot(num_abnormal, ae_err_rate, label = 'CAE')\n",
    "plt.xlabel('Number of abnormal data')\n",
    "plt.ylabel('error rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5701a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77e6ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
