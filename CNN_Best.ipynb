{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f6f48c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c92b1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_epochs = 150\n",
    "learning_rate = 0.002\n",
    "threshold = 0.0011697833045087008\n",
    "classes = ['abnormal','normal']\n",
    "\n",
    "cnn_err_rate = []\n",
    "ae_err_rate = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "866e5582",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_images = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\캡디이미지\\\\CNN_dataset300\\\\abnormal',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "normal_images = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\캡디이미지\\\\CNN_dataset300\\\\normal',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "normal_image_list = []\n",
    "for feature, index in normal_images:\n",
    "    normal_image_list.append([feature, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66205f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 12, 5) \n",
    "        self.conv3 = nn.Conv2d(12, 24, 4)  \n",
    "        self.fc1 = nn.Linear(24 * 25 * 25, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # 6 * 110 * 110\n",
    "        x = self.pool(F.relu(self.conv2(x))) # 12 * 53 * 53\n",
    "        x = self.pool(F.relu(self.conv3(x))) # 24 * 25 * 25\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe075779",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.cnn_layer1 = nn.Sequential(\n",
    "                        nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                         nn.MaxPool2d(2,2))\n",
    "\n",
    "        self.cnn_layer2 = nn.Sequential(\n",
    "                                nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                 nn.MaxPool2d(2,2))\n",
    "        \n",
    "        self.cnn_layer3 = nn.Sequential(\n",
    "                                nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                 nn.MaxPool2d(2,2))\n",
    "\n",
    "        # Decoder        \n",
    "        self.tran_cnn_layer1 = nn.Sequential(\n",
    "                        nn.ConvTranspose2d(64, 32, kernel_size = 2, stride = 2, padding=0),\n",
    "                        nn.ReLU())\n",
    "        \n",
    "        self.tran_cnn_layer2 = nn.Sequential(\n",
    "                        nn.ConvTranspose2d(32, 16, kernel_size = 2, stride = 2, padding=0),\n",
    "                        nn.ReLU())\n",
    "\n",
    "        self.tran_cnn_layer3 = nn.Sequential(\n",
    "                        nn.ConvTranspose2d(16, 3, kernel_size = 2, stride = 2, padding=0),\n",
    "                        nn.Sigmoid())  \n",
    "            \n",
    "    def forward(self, x):\n",
    "        output = self.cnn_layer1(x)\n",
    "        output = self.cnn_layer2(output)\n",
    "        output = self.cnn_layer3(output)        \n",
    "        output = self.tran_cnn_layer1(output)\n",
    "        output = self.tran_cnn_layer2(output)\n",
    "        output = self.tran_cnn_layer3(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b37db2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('Using {} device'.format(device))\n",
    "\n",
    "## 우리 모델\n",
    "AE = ConvAutoEncoder()\n",
    "AE.to(device)\n",
    "AE.load_state_dict(torch.load('best_model_final.pth'))\n",
    "ae_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fb5b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "data_size = [10, 30, 60, 90, 120, 150, 230, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36fcc445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,   150] loss: 0.6992909\n",
      "[1,   150] loss: 0.6924670\n",
      "[2,   150] loss: 0.6861661\n",
      "[3,   150] loss: 0.6801596\n",
      "[4,   150] loss: 0.6746621\n",
      "[5,   150] loss: 0.6691960\n",
      "[6,   150] loss: 0.6653714\n",
      "[7,   150] loss: 0.6592443\n",
      "[8,   150] loss: 0.6562589\n",
      "[9,   150] loss: 0.6520330\n",
      "[10,   150] loss: 0.6478096\n",
      "[11,   150] loss: 0.6436886\n",
      "[12,   150] loss: 0.6367578\n",
      "[13,   150] loss: 0.6353811\n",
      "[14,   150] loss: 0.6280999\n",
      "[15,   150] loss: 0.6237238\n",
      "[16,   150] loss: 0.6194074\n",
      "[17,   150] loss: 0.6150735\n",
      "[18,   150] loss: 0.6150265\n",
      "[19,   150] loss: 0.6068731\n",
      "[20,   150] loss: 0.6026786\n",
      "[21,   150] loss: 0.5984784\n",
      "[22,   150] loss: 0.5943726\n",
      "[23,   150] loss: 0.5956199\n",
      "[24,   150] loss: 0.5862015\n",
      "[25,   150] loss: 0.5938662\n",
      "[26,   150] loss: 0.5782421\n",
      "[27,   150] loss: 0.5802951\n",
      "[28,   150] loss: 0.5766494\n",
      "[29,   150] loss: 0.5659848\n",
      "[30,   150] loss: 0.5616502\n",
      "[31,   150] loss: 0.5646717\n",
      "[32,   150] loss: 0.5528957\n",
      "[33,   150] loss: 0.5566034\n",
      "[34,   150] loss: 0.5526766\n",
      "[35,   150] loss: 0.5486040\n",
      "[36,   150] loss: 0.5443671\n",
      "[37,   150] loss: 0.5398510\n",
      "[38,   150] loss: 0.5352711\n",
      "[39,   150] loss: 0.5302362\n",
      "[40,   150] loss: 0.5249774\n",
      "[41,   150] loss: 0.5193272\n",
      "[42,   150] loss: 0.5260729\n",
      "[43,   150] loss: 0.4954082\n",
      "[44,   150] loss: 0.4875339\n",
      "[45,   150] loss: 0.5093735\n",
      "[46,   150] loss: 0.4735840\n",
      "[47,   150] loss: 0.4656527\n",
      "[48,   150] loss: 0.4584778\n",
      "[49,   150] loss: 0.4710301\n",
      "[50,   150] loss: 0.4477581\n",
      "[51,   150] loss: 0.4650209\n",
      "[52,   150] loss: 0.4422457\n",
      "[53,   150] loss: 0.4385136\n",
      "[54,   150] loss: 0.4605043\n",
      "[55,   150] loss: 0.4839735\n",
      "[56,   150] loss: 0.4598925\n",
      "[57,   150] loss: 0.4606045\n",
      "[58,   150] loss: 0.4599915\n",
      "[59,   150] loss: 0.4366925\n",
      "[60,   150] loss: 0.4366232\n",
      "[61,   150] loss: 0.4608522\n",
      "[62,   150] loss: 0.4363380\n",
      "[63,   150] loss: 0.4863481\n",
      "[64,   150] loss: 0.4601829\n",
      "[65,   150] loss: 0.4859368\n",
      "[66,   150] loss: 0.4601947\n",
      "[67,   150] loss: 0.4369833\n",
      "[68,   150] loss: 0.4585120\n",
      "[69,   150] loss: 0.4379680\n",
      "[70,   150] loss: 0.4604459\n",
      "[71,   150] loss: 0.4348582\n",
      "[72,   150] loss: 0.4594738\n",
      "[73,   150] loss: 0.4604092\n",
      "[74,   150] loss: 0.4591772\n",
      "[75,   150] loss: 0.4345213\n",
      "[76,   150] loss: 0.4873805\n",
      "[77,   150] loss: 0.4595252\n",
      "[78,   150] loss: 0.4351977\n",
      "[79,   150] loss: 0.4345100\n",
      "[80,   150] loss: 0.4855162\n",
      "[81,   150] loss: 0.4338454\n",
      "[82,   150] loss: 0.4609984\n",
      "[83,   150] loss: 0.4600368\n",
      "[84,   150] loss: 0.4338915\n",
      "[85,   150] loss: 0.4584275\n",
      "[86,   150] loss: 0.4583127\n",
      "[87,   150] loss: 0.4582145\n",
      "[88,   150] loss: 0.4851736\n",
      "[89,   150] loss: 0.4352545\n",
      "[90,   150] loss: 0.4342486\n",
      "[91,   150] loss: 0.4603897\n",
      "[92,   150] loss: 0.4585832\n",
      "[93,   150] loss: 0.4338737\n",
      "[94,   150] loss: 0.4846521\n",
      "[95,   150] loss: 0.4589572\n",
      "[96,   150] loss: 0.4335676\n",
      "[97,   150] loss: 0.4334366\n",
      "[98,   150] loss: 0.4579476\n",
      "[99,   150] loss: 0.4581346\n",
      "[100,   150] loss: 0.4577786\n",
      "[101,   150] loss: 0.4328204\n",
      "[102,   150] loss: 0.4339826\n",
      "[103,   150] loss: 0.4862035\n",
      "[104,   150] loss: 0.4583833\n",
      "[105,   150] loss: 0.4615879\n",
      "[106,   150] loss: 0.4348929\n",
      "[107,   150] loss: 0.4581173\n",
      "[108,   150] loss: 0.4332964\n",
      "[109,   150] loss: 0.4598184\n",
      "[110,   150] loss: 0.4579658\n",
      "[111,   150] loss: 0.4583296\n",
      "[112,   150] loss: 0.4577886\n",
      "[113,   150] loss: 0.4582893\n",
      "[114,   150] loss: 0.4321764\n",
      "[115,   150] loss: 0.4572520\n",
      "[116,   150] loss: 0.4320351\n",
      "[117,   150] loss: 0.4338413\n",
      "[118,   150] loss: 0.4579577\n",
      "[119,   150] loss: 0.4565894\n",
      "[120,   150] loss: 0.4333997\n",
      "[121,   150] loss: 0.4349682\n",
      "[122,   150] loss: 0.4583727\n",
      "[123,   150] loss: 0.4576827\n",
      "[124,   150] loss: 0.4331447\n",
      "[125,   150] loss: 0.4324044\n",
      "[126,   150] loss: 0.4325638\n",
      "[127,   150] loss: 0.4842248\n",
      "[128,   150] loss: 0.4326937\n",
      "[129,   150] loss: 0.4835076\n",
      "[130,   150] loss: 0.4323209\n",
      "[131,   150] loss: 0.4574887\n",
      "[132,   150] loss: 0.4585713\n",
      "[133,   150] loss: 0.4841823\n",
      "[134,   150] loss: 0.5079573\n",
      "[135,   150] loss: 0.4578465\n",
      "[136,   150] loss: 0.4338680\n",
      "[137,   150] loss: 0.4562252\n",
      "[138,   150] loss: 0.4333389\n",
      "[139,   150] loss: 0.4345404\n",
      "[140,   150] loss: 0.4325743\n",
      "[141,   150] loss: 0.4573051\n",
      "[142,   150] loss: 0.4567130\n",
      "[143,   150] loss: 0.4564628\n",
      "[144,   150] loss: 0.4313849\n",
      "[145,   150] loss: 0.4316960\n",
      "[146,   150] loss: 0.4305859\n",
      "[147,   150] loss: 0.4314173\n",
      "[148,   150] loss: 0.4326848\n",
      "[149,   150] loss: 0.4573595\n",
      "Finished Training\n",
      "Error rate of test images: 0.166667\n",
      "AE error rate : 0.000000 \n",
      "save model data/[2021-12-28_19-43-47]_best_model_final_0.pth\n",
      "[0,   150] loss: 0.6759340\n",
      "[1,   150] loss: 0.6751657\n",
      "[2,   150] loss: 0.6745135\n",
      "[3,   150] loss: 0.6739835\n",
      "[4,   150] loss: 0.6733714\n",
      "[5,   150] loss: 0.6727462\n",
      "[6,   150] loss: 0.6722068\n",
      "[7,   150] loss: 0.6717876\n",
      "[8,   150] loss: 0.6713240\n",
      "[9,   150] loss: 0.6709024\n",
      "[10,   150] loss: 0.6705117\n",
      "[11,   150] loss: 0.6701912\n",
      "[12,   150] loss: 0.6696414\n",
      "[13,   150] loss: 0.6694809\n",
      "[14,   150] loss: 0.6690556\n",
      "[15,   150] loss: 0.6686678\n",
      "[16,   150] loss: 0.6683687\n",
      "[17,   150] loss: 0.6680819\n",
      "[18,   150] loss: 0.6678351\n",
      "[19,   150] loss: 0.6675776\n",
      "[20,   150] loss: 0.6671885\n",
      "[21,   150] loss: 0.6669358\n",
      "[22,   150] loss: 0.6667101\n",
      "[23,   150] loss: 0.6664405\n",
      "[24,   150] loss: 0.6661095\n",
      "[25,   150] loss: 0.6658826\n",
      "[26,   150] loss: 0.6655609\n",
      "[27,   150] loss: 0.6653893\n",
      "[28,   150] loss: 0.6651435\n",
      "[29,   150] loss: 0.6650223\n",
      "[30,   150] loss: 0.6646395\n",
      "[31,   150] loss: 0.6644092\n",
      "[32,   150] loss: 0.6642230\n",
      "[33,   150] loss: 0.6639878\n",
      "[34,   150] loss: 0.6636666\n",
      "[35,   150] loss: 0.6635436\n",
      "[36,   150] loss: 0.6632685\n",
      "[37,   150] loss: 0.6631236\n",
      "[38,   150] loss: 0.6628070\n",
      "[39,   150] loss: 0.6626580\n",
      "[40,   150] loss: 0.6626991\n",
      "[41,   150] loss: 0.6622157\n",
      "[42,   150] loss: 0.6623067\n",
      "[43,   150] loss: 0.6620425\n",
      "[44,   150] loss: 0.6618252\n",
      "[45,   150] loss: 0.6616485\n",
      "[46,   150] loss: 0.6614694\n",
      "[47,   150] loss: 0.6615178\n",
      "[48,   150] loss: 0.6610956\n",
      "[49,   150] loss: 0.6610085\n",
      "[50,   150] loss: 0.6608762\n",
      "[51,   150] loss: 0.6608703\n",
      "[52,   150] loss: 0.6608689\n",
      "[53,   150] loss: 0.6604981\n",
      "[54,   150] loss: 0.6603441\n",
      "[55,   150] loss: 0.6600873\n",
      "[56,   150] loss: 0.6600904\n",
      "[57,   150] loss: 0.6599368\n",
      "[58,   150] loss: 0.6596126\n",
      "[59,   150] loss: 0.6594909\n",
      "[60,   150] loss: 0.6593154\n",
      "[61,   150] loss: 0.6592470\n",
      "[62,   150] loss: 0.6589854\n",
      "[63,   150] loss: 0.6592570\n",
      "[64,   150] loss: 0.6587313\n",
      "[65,   150] loss: 0.6587183\n",
      "[66,   150] loss: 0.6585307\n",
      "[67,   150] loss: 0.6584295\n",
      "[68,   150] loss: 0.6585703\n",
      "[69,   150] loss: 0.6586880\n",
      "[70,   150] loss: 0.6581085\n",
      "[71,   150] loss: 0.6582647\n",
      "[72,   150] loss: 0.6580038\n",
      "[73,   150] loss: 0.6579321\n",
      "[74,   150] loss: 0.6578622\n",
      "[75,   150] loss: 0.6575637\n",
      "[76,   150] loss: 0.6575086\n",
      "[77,   150] loss: 0.6572563\n",
      "[78,   150] loss: 0.6569146\n",
      "[79,   150] loss: 0.6570324\n",
      "[80,   150] loss: 0.6571477\n",
      "[81,   150] loss: 0.6566325\n",
      "[82,   150] loss: 0.6566555\n",
      "[83,   150] loss: 0.6564897\n",
      "[84,   150] loss: 0.6561403\n",
      "[85,   150] loss: 0.6563402\n",
      "[86,   150] loss: 0.6561374\n",
      "[87,   150] loss: 0.6556823\n",
      "[88,   150] loss: 0.6557148\n",
      "[89,   150] loss: 0.6559215\n",
      "[90,   150] loss: 0.6557471\n",
      "[91,   150] loss: 0.6549793\n",
      "[92,   150] loss: 0.6556912\n",
      "[93,   150] loss: 0.6547236\n",
      "[94,   150] loss: 0.6545686\n",
      "[95,   150] loss: 0.6542249\n",
      "[96,   150] loss: 0.6546383\n",
      "[97,   150] loss: 0.6545475\n",
      "[98,   150] loss: 0.6543586\n",
      "[99,   150] loss: 0.6537888\n",
      "[100,   150] loss: 0.6534334\n",
      "[101,   150] loss: 0.6536771\n",
      "[102,   150] loss: 0.6528536\n",
      "[103,   150] loss: 0.6533490\n",
      "[104,   150] loss: 0.6524860\n",
      "[105,   150] loss: 0.6522256\n",
      "[106,   150] loss: 0.6523130\n",
      "[107,   150] loss: 0.6522324\n",
      "[108,   150] loss: 0.6511221\n",
      "[109,   150] loss: 0.6512114\n",
      "[110,   150] loss: 0.6508390\n",
      "[111,   150] loss: 0.6511558\n",
      "[112,   150] loss: 0.6504794\n",
      "[113,   150] loss: 0.6512105\n",
      "[114,   150] loss: 0.6496105\n",
      "[115,   150] loss: 0.6493408\n",
      "[116,   150] loss: 0.6490857\n",
      "[117,   150] loss: 0.6483467\n",
      "[118,   150] loss: 0.6474261\n",
      "[119,   150] loss: 0.6472578\n",
      "[120,   150] loss: 0.6468874\n",
      "[121,   150] loss: 0.6468759\n",
      "[122,   150] loss: 0.6456910\n",
      "[123,   150] loss: 0.6453128\n",
      "[124,   150] loss: 0.6459551\n",
      "[125,   150] loss: 0.6439066\n",
      "[126,   150] loss: 0.6444933\n",
      "[127,   150] loss: 0.6445530\n",
      "[128,   150] loss: 0.6428014\n",
      "[129,   150] loss: 0.6424776\n",
      "[130,   150] loss: 0.6408488\n",
      "[131,   150] loss: 0.6405098\n",
      "[132,   150] loss: 0.6398399\n",
      "[133,   150] loss: 0.6394262\n",
      "[134,   150] loss: 0.6387510\n",
      "[135,   150] loss: 0.6376751\n",
      "[136,   150] loss: 0.6378528\n",
      "[137,   150] loss: 0.6354006\n",
      "[138,   150] loss: 0.6347717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[139,   150] loss: 0.6336803\n",
      "[140,   150] loss: 0.6342333\n",
      "[141,   150] loss: 0.6304709\n",
      "[142,   150] loss: 0.6285082\n",
      "[143,   150] loss: 0.6277133\n",
      "[144,   150] loss: 0.6239430\n",
      "[145,   150] loss: 0.6248819\n",
      "[146,   150] loss: 0.6225315\n",
      "[147,   150] loss: 0.6234559\n",
      "[148,   150] loss: 0.6169005\n",
      "[149,   150] loss: 0.6144858\n",
      "Finished Training\n",
      "Error rate of test images: 0.375000\n",
      "AE error rate : 0.000000 \n",
      "save model data/[2021-12-28_19-43-47]_best_model_final_1.pth\n",
      "[0,   150] loss: 0.6947756\n",
      "[1,   150] loss: 0.6940608\n",
      "[2,   150] loss: 0.6937089\n",
      "[3,   150] loss: 0.6932389\n",
      "[4,   150] loss: 0.6928713\n",
      "[5,   150] loss: 0.6926747\n",
      "[6,   150] loss: 0.6924439\n",
      "[7,   150] loss: 0.6919803\n",
      "[8,   150] loss: 0.6917549\n",
      "[9,   150] loss: 0.6915015\n",
      "[10,   150] loss: 0.6912858\n",
      "[11,   150] loss: 0.6908820\n",
      "[12,   150] loss: 0.6909426\n",
      "[13,   150] loss: 0.6909707\n",
      "[14,   150] loss: 0.6903858\n",
      "[15,   150] loss: 0.6909289\n",
      "[16,   150] loss: 0.6901353\n",
      "[17,   150] loss: 0.6898238\n",
      "[18,   150] loss: 0.6899411\n",
      "[19,   150] loss: 0.6900447\n",
      "[20,   150] loss: 0.6894227\n",
      "[21,   150] loss: 0.6899242\n",
      "[22,   150] loss: 0.6896738\n",
      "[23,   150] loss: 0.6894562\n",
      "[24,   150] loss: 0.6891863\n",
      "[25,   150] loss: 0.6891610\n",
      "[26,   150] loss: 0.6895215\n",
      "[27,   150] loss: 0.6892992\n",
      "[28,   150] loss: 0.6885970\n",
      "[29,   150] loss: 0.6888291\n",
      "[30,   150] loss: 0.6884645\n",
      "[31,   150] loss: 0.6887290\n",
      "[32,   150] loss: 0.6890534\n",
      "[33,   150] loss: 0.6884288\n",
      "[34,   150] loss: 0.6893511\n",
      "[35,   150] loss: 0.6885319\n",
      "[36,   150] loss: 0.6877378\n",
      "[37,   150] loss: 0.6880268\n",
      "[38,   150] loss: 0.6882826\n",
      "[39,   150] loss: 0.6879830\n",
      "[40,   150] loss: 0.6882690\n",
      "[41,   150] loss: 0.6878875\n",
      "[42,   150] loss: 0.6881025\n",
      "[43,   150] loss: 0.6880525\n",
      "[44,   150] loss: 0.6876019\n",
      "[45,   150] loss: 0.6870522\n",
      "[46,   150] loss: 0.6880529\n",
      "[47,   150] loss: 0.6880635\n",
      "[48,   150] loss: 0.6879048\n",
      "[49,   150] loss: 0.6873033\n",
      "[50,   150] loss: 0.6864711\n",
      "[51,   150] loss: 0.6878034\n",
      "[52,   150] loss: 0.6873974\n",
      "[53,   150] loss: 0.6877131\n",
      "[54,   150] loss: 0.6886474\n",
      "[55,   150] loss: 0.6877702\n",
      "[56,   150] loss: 0.6872307\n",
      "[57,   150] loss: 0.6862356\n",
      "[58,   150] loss: 0.6860787\n",
      "[59,   150] loss: 0.6864798\n",
      "[60,   150] loss: 0.6871156\n",
      "[61,   150] loss: 0.6858688\n",
      "[62,   150] loss: 0.6868577\n",
      "[63,   150] loss: 0.6868571\n",
      "[64,   150] loss: 0.6883872\n",
      "[65,   150] loss: 0.6877525\n",
      "[66,   150] loss: 0.6867445\n",
      "[67,   150] loss: 0.6873133\n",
      "[68,   150] loss: 0.6870224\n",
      "[69,   150] loss: 0.6871964\n",
      "[70,   150] loss: 0.6860684\n",
      "[71,   150] loss: 0.6858905\n",
      "[72,   150] loss: 0.6877844\n",
      "[73,   150] loss: 0.6869660\n",
      "[74,   150] loss: 0.6870119\n",
      "[75,   150] loss: 0.6862256\n",
      "[76,   150] loss: 0.6863144\n",
      "[77,   150] loss: 0.6857419\n",
      "[78,   150] loss: 0.6863412\n",
      "[79,   150] loss: 0.6867047\n",
      "[80,   150] loss: 0.6866227\n",
      "[81,   150] loss: 0.6860312\n",
      "[82,   150] loss: 0.6873309\n",
      "[83,   150] loss: 0.6857977\n",
      "[84,   150] loss: 0.6863440\n",
      "[85,   150] loss: 0.6864831\n",
      "[86,   150] loss: 0.6858353\n",
      "[87,   150] loss: 0.6859101\n",
      "[88,   150] loss: 0.6877190\n",
      "[89,   150] loss: 0.6864358\n",
      "[90,   150] loss: 0.6851666\n",
      "[91,   150] loss: 0.6849754\n",
      "[92,   150] loss: 0.6865971\n",
      "[93,   150] loss: 0.6866379\n",
      "[94,   150] loss: 0.6853203\n",
      "[95,   150] loss: 0.6860009\n",
      "[96,   150] loss: 0.6859414\n",
      "[97,   150] loss: 0.6861038\n",
      "[98,   150] loss: 0.6853994\n",
      "[99,   150] loss: 0.6871862\n",
      "[100,   150] loss: 0.6851569\n",
      "[101,   150] loss: 0.6858461\n",
      "[102,   150] loss: 0.6840761\n",
      "[103,   150] loss: 0.6866866\n",
      "[104,   150] loss: 0.6850462\n",
      "[105,   150] loss: 0.6858786\n",
      "[106,   150] loss: 0.6858585\n",
      "[107,   150] loss: 0.6848833\n",
      "[108,   150] loss: 0.6852533\n",
      "[109,   150] loss: 0.6853790\n",
      "[110,   150] loss: 0.6836243\n",
      "[111,   150] loss: 0.6851015\n",
      "[112,   150] loss: 0.6843170\n",
      "[113,   150] loss: 0.6859309\n",
      "[114,   150] loss: 0.6844212\n",
      "[115,   150] loss: 0.6843609\n",
      "[116,   150] loss: 0.6834904\n",
      "[117,   150] loss: 0.6849003\n",
      "[118,   150] loss: 0.6833186\n",
      "[119,   150] loss: 0.6839930\n",
      "[120,   150] loss: 0.6847625\n",
      "[121,   150] loss: 0.6859593\n",
      "[122,   150] loss: 0.6826172\n",
      "[123,   150] loss: 0.6847496\n",
      "[124,   150] loss: 0.6831111\n",
      "[125,   150] loss: 0.6826055\n",
      "[126,   150] loss: 0.6829881\n",
      "[127,   150] loss: 0.6832322\n",
      "[128,   150] loss: 0.6838897\n",
      "[129,   150] loss: 0.6835057\n",
      "[130,   150] loss: 0.6824467\n",
      "[131,   150] loss: 0.6831976\n",
      "[132,   150] loss: 0.6817802\n",
      "[133,   150] loss: 0.6813380\n",
      "[134,   150] loss: 0.6819561\n",
      "[135,   150] loss: 0.6821387\n",
      "[136,   150] loss: 0.6832850\n",
      "[137,   150] loss: 0.6813386\n",
      "[138,   150] loss: 0.6806841\n",
      "[139,   150] loss: 0.6802280\n",
      "[140,   150] loss: 0.6808313\n",
      "[141,   150] loss: 0.6818781\n",
      "[142,   150] loss: 0.6813032\n",
      "[143,   150] loss: 0.6792726\n",
      "[144,   150] loss: 0.6795879\n",
      "[145,   150] loss: 0.6805351\n",
      "[146,   150] loss: 0.6785547\n",
      "[147,   150] loss: 0.6792636\n",
      "[148,   150] loss: 0.6790558\n",
      "[149,   150] loss: 0.6783641\n",
      "Finished Training\n",
      "Error rate of test images: 0.454545\n",
      "AE error rate : 0.000000 \n",
      "save model data/[2021-12-28_19-43-47]_best_model_final_2.pth\n",
      "[0,   150] loss: 0.6941257\n",
      "[1,   150] loss: 0.6902768\n",
      "[2,   150] loss: 0.6871724\n",
      "[3,   150] loss: 0.6851140\n",
      "[4,   150] loss: 0.6813489\n",
      "[5,   150] loss: 0.6804002\n",
      "[6,   150] loss: 0.6802727\n",
      "[7,   150] loss: 0.6754268\n",
      "[8,   150] loss: 0.6744980\n",
      "[9,   150] loss: 0.6729388\n",
      "[10,   150] loss: 0.6715310\n",
      "[11,   150] loss: 0.6701380\n",
      "[12,   150] loss: 0.6702706\n",
      "[13,   150] loss: 0.6661550\n",
      "[14,   150] loss: 0.6678477\n",
      "[15,   150] loss: 0.6633071\n",
      "[16,   150] loss: 0.6669941\n",
      "[17,   150] loss: 0.6639832\n",
      "[18,   150] loss: 0.6608515\n",
      "[19,   150] loss: 0.6593693\n",
      "[20,   150] loss: 0.6582319\n",
      "[21,   150] loss: 0.6569321\n",
      "[22,   150] loss: 0.6557511\n",
      "[23,   150] loss: 0.6572514\n",
      "[24,   150] loss: 0.6590446\n",
      "[25,   150] loss: 0.6531936\n",
      "[26,   150] loss: 0.6498854\n",
      "[27,   150] loss: 0.6513168\n",
      "[28,   150] loss: 0.6475528\n",
      "[29,   150] loss: 0.6495060\n",
      "[30,   150] loss: 0.6552161\n",
      "[31,   150] loss: 0.6546762\n",
      "[32,   150] loss: 0.6477322\n",
      "[33,   150] loss: 0.6537292\n",
      "[34,   150] loss: 0.6504737\n",
      "[35,   150] loss: 0.6429659\n",
      "[36,   150] loss: 0.6419065\n",
      "[37,   150] loss: 0.6484175\n",
      "[38,   150] loss: 0.6558414\n",
      "[39,   150] loss: 0.6440335\n",
      "[40,   150] loss: 0.6436527\n",
      "[41,   150] loss: 0.6488603\n",
      "[42,   150] loss: 0.6436567\n",
      "[43,   150] loss: 0.6424235\n",
      "[44,   150] loss: 0.6461610\n",
      "[45,   150] loss: 0.6414307\n",
      "[46,   150] loss: 0.6425715\n",
      "[47,   150] loss: 0.6527230\n",
      "[48,   150] loss: 0.6398481\n",
      "[49,   150] loss: 0.6383011\n",
      "[50,   150] loss: 0.6431757\n",
      "[51,   150] loss: 0.6335824\n",
      "[52,   150] loss: 0.6355231\n",
      "[53,   150] loss: 0.6345456\n",
      "[54,   150] loss: 0.6378325\n",
      "[55,   150] loss: 0.6322063\n",
      "[56,   150] loss: 0.6381118\n",
      "[57,   150] loss: 0.6340278\n",
      "[58,   150] loss: 0.6322736\n",
      "[59,   150] loss: 0.6267132\n",
      "[60,   150] loss: 0.6245177\n",
      "[61,   150] loss: 0.6250479\n",
      "[62,   150] loss: 0.6190318\n",
      "[63,   150] loss: 0.6112991\n",
      "[64,   150] loss: 0.6147672\n",
      "[65,   150] loss: 0.6088257\n",
      "[66,   150] loss: 0.6031064\n",
      "[67,   150] loss: 0.5909853\n",
      "[68,   150] loss: 0.5832495\n",
      "[69,   150] loss: 0.5733966\n",
      "[70,   150] loss: 0.5560895\n",
      "[71,   150] loss: 0.5440449\n",
      "[72,   150] loss: 0.5134085\n",
      "[73,   150] loss: 0.4765426\n",
      "[74,   150] loss: 0.4330013\n",
      "[75,   150] loss: 0.3706518\n",
      "[76,   150] loss: 0.2996713\n",
      "[77,   150] loss: 0.2197171\n",
      "[78,   150] loss: 0.1540763\n",
      "[79,   150] loss: 0.1035314\n",
      "[80,   150] loss: 0.0728948\n",
      "[81,   150] loss: 0.0508739\n",
      "[82,   150] loss: 0.0375904\n",
      "[83,   150] loss: 0.0287238\n",
      "[84,   150] loss: 0.0225484\n",
      "[85,   150] loss: 0.0183663\n",
      "[86,   150] loss: 0.0152131\n",
      "[87,   150] loss: 0.0127901\n",
      "[88,   150] loss: 0.0110682\n",
      "[89,   150] loss: 0.0095544\n",
      "[90,   150] loss: 0.0083540\n",
      "[91,   150] loss: 0.0075094\n",
      "[92,   150] loss: 0.0067456\n",
      "[93,   150] loss: 0.0062388\n",
      "[94,   150] loss: 0.0056478\n",
      "[95,   150] loss: 0.0051771\n",
      "[96,   150] loss: 0.0047012\n",
      "[97,   150] loss: 0.0043337\n",
      "[98,   150] loss: 0.0039082\n",
      "[99,   150] loss: 0.0036302\n",
      "[100,   150] loss: 0.0036011\n",
      "[101,   150] loss: 0.0031990\n",
      "[102,   150] loss: 0.0029878\n",
      "[103,   150] loss: 0.0028386\n",
      "[104,   150] loss: 0.0027597\n",
      "[105,   150] loss: 0.0025904\n",
      "[106,   150] loss: 0.0024128\n",
      "[107,   150] loss: 0.0022714\n",
      "[108,   150] loss: 0.0021553\n",
      "[109,   150] loss: 0.0021215\n",
      "[110,   150] loss: 0.0019832\n",
      "[111,   150] loss: 0.0018992\n",
      "[112,   150] loss: 0.0018764\n",
      "[113,   150] loss: 0.0017505\n",
      "[114,   150] loss: 0.0016782\n",
      "[115,   150] loss: 0.0016198\n",
      "[116,   150] loss: 0.0015977\n",
      "[117,   150] loss: 0.0015020\n",
      "[118,   150] loss: 0.0014364\n",
      "[119,   150] loss: 0.0013970\n",
      "[120,   150] loss: 0.0013478\n",
      "[121,   150] loss: 0.0013132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[122,   150] loss: 0.0012735\n",
      "[123,   150] loss: 0.0012268\n",
      "[124,   150] loss: 0.0011864\n",
      "[125,   150] loss: 0.0011393\n",
      "[126,   150] loss: 0.0011117\n",
      "[127,   150] loss: 0.0010778\n",
      "[128,   150] loss: 0.0010650\n",
      "[129,   150] loss: 0.0010390\n",
      "[130,   150] loss: 0.0009924\n",
      "[131,   150] loss: 0.0009737\n",
      "[132,   150] loss: 0.0009543\n",
      "[133,   150] loss: 0.0009221\n",
      "[134,   150] loss: 0.0009119\n",
      "[135,   150] loss: 0.0008761\n",
      "[136,   150] loss: 0.0008587\n",
      "[137,   150] loss: 0.0008368\n",
      "[138,   150] loss: 0.0008246\n",
      "[139,   150] loss: 0.0008055\n",
      "[140,   150] loss: 0.0007781\n",
      "[141,   150] loss: 0.0007955\n",
      "[142,   150] loss: 0.0007511\n",
      "[143,   150] loss: 0.0007552\n",
      "[144,   150] loss: 0.0007161\n",
      "[145,   150] loss: 0.0007248\n",
      "[146,   150] loss: 0.0006889\n",
      "[147,   150] loss: 0.0006712\n",
      "[148,   150] loss: 0.0006630\n",
      "[149,   150] loss: 0.0006518\n",
      "Finished Training\n",
      "Error rate of test images: 0.000000\n",
      "AE error rate : 0.000000 \n",
      "save model data/[2021-12-28_19-43-47]_best_model_final_3.pth\n",
      "[0,   150] loss: 0.7274916\n",
      "[1,   150] loss: 0.7222668\n",
      "[2,   150] loss: 0.7112970\n",
      "[3,   150] loss: 0.6999844\n",
      "[4,   150] loss: 0.6902548\n",
      "[5,   150] loss: 0.6804588\n",
      "[6,   150] loss: 0.6667625\n",
      "[7,   150] loss: 0.6570859\n",
      "[8,   150] loss: 0.6392155\n",
      "[9,   150] loss: 0.6218812\n",
      "[10,   150] loss: 0.6060576\n",
      "[11,   150] loss: 0.6223977\n",
      "[12,   150] loss: 0.5946134\n",
      "[13,   150] loss: 0.6079137\n",
      "[14,   150] loss: 0.5900393\n",
      "[15,   150] loss: 0.5894911\n",
      "[16,   150] loss: 0.6058849\n",
      "[17,   150] loss: 0.6174221\n",
      "[18,   150] loss: 0.6050103\n",
      "[19,   150] loss: 0.5906408\n",
      "[20,   150] loss: 0.6046678\n",
      "[21,   150] loss: 0.6014683\n",
      "[22,   150] loss: 0.6005762\n",
      "[23,   150] loss: 0.6018048\n",
      "[24,   150] loss: 0.5863669\n",
      "[25,   150] loss: 0.5841378\n",
      "[26,   150] loss: 0.5993879\n",
      "[27,   150] loss: 0.5838375\n",
      "[28,   150] loss: 0.5979144\n",
      "[29,   150] loss: 0.5960265\n",
      "[30,   150] loss: 0.5801116\n",
      "[31,   150] loss: 0.5938818\n",
      "[32,   150] loss: 0.5781123\n",
      "[33,   150] loss: 0.5910264\n",
      "[34,   150] loss: 0.5755499\n",
      "[35,   150] loss: 0.6016935\n",
      "[36,   150] loss: 0.5878104\n",
      "[37,   150] loss: 0.5842564\n",
      "[38,   150] loss: 0.5675313\n",
      "[39,   150] loss: 0.5650029\n",
      "[40,   150] loss: 0.5754101\n",
      "[41,   150] loss: 0.5708875\n",
      "[42,   150] loss: 0.5531129\n",
      "[43,   150] loss: 0.5508913\n",
      "[44,   150] loss: 0.5582336\n",
      "[45,   150] loss: 0.5528893\n",
      "[46,   150] loss: 0.5422572\n",
      "[47,   150] loss: 0.5353903\n",
      "[48,   150] loss: 0.5011200\n",
      "[49,   150] loss: 0.4923906\n",
      "[50,   150] loss: 0.4747699\n",
      "[51,   150] loss: 0.4776434\n",
      "[52,   150] loss: 0.4301156\n",
      "[53,   150] loss: 0.4108278\n",
      "[54,   150] loss: 0.3580993\n",
      "[55,   150] loss: 0.2796856\n",
      "[56,   150] loss: 0.2166123\n",
      "[57,   150] loss: 0.1689453\n",
      "[58,   150] loss: 0.1282096\n",
      "[59,   150] loss: 0.0774076\n",
      "[60,   150] loss: 0.0538978\n",
      "[61,   150] loss: 0.0403055\n",
      "[62,   150] loss: 0.0295911\n",
      "[63,   150] loss: 0.0225053\n",
      "[64,   150] loss: 0.0180821\n",
      "[65,   150] loss: 0.0150470\n",
      "[66,   150] loss: 0.0121631\n",
      "[67,   150] loss: 0.0101617\n",
      "[68,   150] loss: 0.0092908\n",
      "[69,   150] loss: 0.0080306\n",
      "[70,   150] loss: 0.0069783\n",
      "[71,   150] loss: 0.0065330\n",
      "[72,   150] loss: 0.0057453\n",
      "[73,   150] loss: 0.0050549\n",
      "[74,   150] loss: 0.0044959\n",
      "[75,   150] loss: 0.0041473\n",
      "[76,   150] loss: 0.0039422\n",
      "[77,   150] loss: 0.0035713\n",
      "[78,   150] loss: 0.0033093\n",
      "[79,   150] loss: 0.0031073\n",
      "[80,   150] loss: 0.0029321\n",
      "[81,   150] loss: 0.0026817\n",
      "[82,   150] loss: 0.0025496\n",
      "[83,   150] loss: 0.0024037\n",
      "[84,   150] loss: 0.0024702\n",
      "[85,   150] loss: 0.0021648\n",
      "[86,   150] loss: 0.0020740\n",
      "[87,   150] loss: 0.0019679\n",
      "[88,   150] loss: 0.0018560\n",
      "[89,   150] loss: 0.0017821\n",
      "[90,   150] loss: 0.0017481\n",
      "[91,   150] loss: 0.0016314\n",
      "[92,   150] loss: 0.0017342\n",
      "[93,   150] loss: 0.0015215\n",
      "[94,   150] loss: 0.0014514\n",
      "[95,   150] loss: 0.0014323\n",
      "[96,   150] loss: 0.0013707\n",
      "[97,   150] loss: 0.0012859\n",
      "[98,   150] loss: 0.0012359\n",
      "[99,   150] loss: 0.0012052\n",
      "[100,   150] loss: 0.0011631\n",
      "[101,   150] loss: 0.0011539\n",
      "[102,   150] loss: 0.0010861\n",
      "[103,   150] loss: 0.0010958\n",
      "[104,   150] loss: 0.0010517\n",
      "[105,   150] loss: 0.0009829\n",
      "[106,   150] loss: 0.0009724\n",
      "[107,   150] loss: 0.0009391\n",
      "[108,   150] loss: 0.0009150\n",
      "[109,   150] loss: 0.0008885\n",
      "[110,   150] loss: 0.0008572\n",
      "[111,   150] loss: 0.0008302\n",
      "[112,   150] loss: 0.0008297\n",
      "[113,   150] loss: 0.0008233\n",
      "[114,   150] loss: 0.0007843\n",
      "[115,   150] loss: 0.0007500\n",
      "[116,   150] loss: 0.0007474\n",
      "[117,   150] loss: 0.0007199\n",
      "[118,   150] loss: 0.0007010\n",
      "[119,   150] loss: 0.0006893\n",
      "[120,   150] loss: 0.0007055\n",
      "[121,   150] loss: 0.0007150\n",
      "[122,   150] loss: 0.0006540\n",
      "[123,   150] loss: 0.0006309\n",
      "[124,   150] loss: 0.0006246\n",
      "[125,   150] loss: 0.0006030\n",
      "[126,   150] loss: 0.0005963\n",
      "[127,   150] loss: 0.0005796\n",
      "[128,   150] loss: 0.0005680\n",
      "[129,   150] loss: 0.0005663\n",
      "[130,   150] loss: 0.0005603\n",
      "[131,   150] loss: 0.0005477\n",
      "[132,   150] loss: 0.0005330\n",
      "[133,   150] loss: 0.0005226\n",
      "[134,   150] loss: 0.0005096\n",
      "[135,   150] loss: 0.0005070\n",
      "[136,   150] loss: 0.0005187\n",
      "[137,   150] loss: 0.0004868\n",
      "[138,   150] loss: 0.0004789\n",
      "[139,   150] loss: 0.0004791\n",
      "[140,   150] loss: 0.0004594\n",
      "[141,   150] loss: 0.0004535\n",
      "[142,   150] loss: 0.0004476\n",
      "[143,   150] loss: 0.0004390\n",
      "[144,   150] loss: 0.0004308\n",
      "[145,   150] loss: 0.0004346\n",
      "[146,   150] loss: 0.0004243\n",
      "[147,   150] loss: 0.0004119\n",
      "[148,   150] loss: 0.0004098\n",
      "[149,   150] loss: 0.0004005\n",
      "Finished Training\n",
      "Error rate of test images: 0.000000\n",
      "AE error rate : 0.000000 \n",
      "save model data/[2021-12-28_19-43-47]_best_model_final_4.pth\n",
      "[0,   150] loss: 0.6816350\n",
      "[1,   150] loss: 0.6720230\n",
      "[2,   150] loss: 0.6630460\n",
      "[3,   150] loss: 0.6542361\n",
      "[4,   150] loss: 0.6455816\n",
      "[5,   150] loss: 0.6375678\n",
      "[6,   150] loss: 0.6295469\n",
      "[7,   150] loss: 0.6213854\n",
      "[8,   150] loss: 0.6129947\n",
      "[9,   150] loss: 0.6039393\n",
      "[10,   150] loss: 0.5941129\n",
      "[11,   150] loss: 0.5840101\n",
      "[12,   150] loss: 0.5744462\n",
      "[13,   150] loss: 0.5672069\n",
      "[14,   150] loss: 0.5635279\n",
      "[15,   150] loss: 0.5613006\n",
      "[16,   150] loss: 0.5606634\n",
      "[17,   150] loss: 0.5600168\n",
      "[18,   150] loss: 0.5603127\n",
      "[19,   150] loss: 0.5600016\n",
      "[20,   150] loss: 0.5593020\n",
      "[21,   150] loss: 0.5589043\n",
      "[22,   150] loss: 0.5589258\n",
      "[23,   150] loss: 0.5589129\n",
      "[24,   150] loss: 0.5580179\n",
      "[25,   150] loss: 0.5586300\n",
      "[26,   150] loss: 0.5584480\n",
      "[27,   150] loss: 0.5588853\n",
      "[28,   150] loss: 0.5572471\n",
      "[29,   150] loss: 0.5571171\n",
      "[30,   150] loss: 0.5574169\n",
      "[31,   150] loss: 0.5570237\n",
      "[32,   150] loss: 0.5564010\n",
      "[33,   150] loss: 0.5555067\n",
      "[34,   150] loss: 0.5556083\n",
      "[35,   150] loss: 0.5550413\n",
      "[36,   150] loss: 0.5543516\n",
      "[37,   150] loss: 0.5552416\n",
      "[38,   150] loss: 0.5529819\n",
      "[39,   150] loss: 0.5532225\n",
      "[40,   150] loss: 0.5522087\n",
      "[41,   150] loss: 0.5522113\n",
      "[42,   150] loss: 0.5516483\n",
      "[43,   150] loss: 0.5507393\n",
      "[44,   150] loss: 0.5492170\n",
      "[45,   150] loss: 0.5487386\n",
      "[46,   150] loss: 0.5476395\n",
      "[47,   150] loss: 0.5468196\n",
      "[48,   150] loss: 0.5456288\n",
      "[49,   150] loss: 0.5451030\n",
      "[50,   150] loss: 0.5440829\n",
      "[51,   150] loss: 0.5413852\n",
      "[52,   150] loss: 0.5409724\n",
      "[53,   150] loss: 0.5387322\n",
      "[54,   150] loss: 0.5375277\n",
      "[55,   150] loss: 0.5339201\n",
      "[56,   150] loss: 0.5323030\n",
      "[57,   150] loss: 0.5311256\n",
      "[58,   150] loss: 0.5280567\n",
      "[59,   150] loss: 0.5260550\n",
      "[60,   150] loss: 0.5223844\n",
      "[61,   150] loss: 0.5201362\n",
      "[62,   150] loss: 0.5165198\n",
      "[63,   150] loss: 0.5136337\n",
      "[64,   150] loss: 0.5106226\n",
      "[65,   150] loss: 0.5068408\n",
      "[66,   150] loss: 0.5039130\n",
      "[67,   150] loss: 0.5001514\n",
      "[68,   150] loss: 0.4958981\n",
      "[69,   150] loss: 0.4945987\n",
      "[70,   150] loss: 0.4907089\n",
      "[71,   150] loss: 0.4874561\n",
      "[72,   150] loss: 0.4851492\n",
      "[73,   150] loss: 0.4827485\n",
      "[74,   150] loss: 0.4806684\n",
      "[75,   150] loss: 0.4777671\n",
      "[76,   150] loss: 0.4772492\n",
      "[77,   150] loss: 0.4747423\n",
      "[78,   150] loss: 0.4733276\n",
      "[79,   150] loss: 0.4709356\n",
      "[80,   150] loss: 0.4682393\n",
      "[81,   150] loss: 0.4661271\n",
      "[82,   150] loss: 0.4638098\n",
      "[83,   150] loss: 0.4625079\n",
      "[84,   150] loss: 0.4594216\n",
      "[85,   150] loss: 0.4581638\n",
      "[86,   150] loss: 0.4565615\n",
      "[87,   150] loss: 0.4551258\n",
      "[88,   150] loss: 0.4526825\n",
      "[89,   150] loss: 0.4507260\n",
      "[90,   150] loss: 0.4487536\n",
      "[91,   150] loss: 0.4469874\n",
      "[92,   150] loss: 0.4447215\n",
      "[93,   150] loss: 0.4433982\n",
      "[94,   150] loss: 0.4411028\n",
      "[95,   150] loss: 0.4390147\n",
      "[96,   150] loss: 0.4360251\n",
      "[97,   150] loss: 0.4346328\n",
      "[98,   150] loss: 0.4317833\n",
      "[99,   150] loss: 0.4285155\n",
      "[100,   150] loss: 0.4264135\n",
      "[101,   150] loss: 0.4208996\n",
      "[102,   150] loss: 0.4238205\n",
      "[103,   150] loss: 0.4160003\n",
      "[104,   150] loss: 0.4122304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[105,   150] loss: 0.4104472\n",
      "[106,   150] loss: 0.4041451\n",
      "[107,   150] loss: 0.3998193\n",
      "[108,   150] loss: 0.3954746\n",
      "[109,   150] loss: 0.3911270\n",
      "[110,   150] loss: 0.3828319\n",
      "[111,   150] loss: 0.3762648\n",
      "[112,   150] loss: 0.3694248\n",
      "[113,   150] loss: 0.3628472\n",
      "[114,   150] loss: 0.3546759\n",
      "[115,   150] loss: 0.3418594\n",
      "[116,   150] loss: 0.3363437\n",
      "[117,   150] loss: 0.3236106\n",
      "[118,   150] loss: 0.3165368\n",
      "[119,   150] loss: 0.2928149\n",
      "[120,   150] loss: 0.2920338\n",
      "[121,   150] loss: 0.2698290\n",
      "[122,   150] loss: 0.2522808\n",
      "[123,   150] loss: 0.2330635\n",
      "[124,   150] loss: 0.2240776\n",
      "[125,   150] loss: 0.2104395\n",
      "[126,   150] loss: 0.2005908\n",
      "[127,   150] loss: 0.2265922\n",
      "[128,   150] loss: 0.1562081\n",
      "[129,   150] loss: 0.1586806\n",
      "[130,   150] loss: 0.1456346\n",
      "[131,   150] loss: 0.1732419\n",
      "[132,   150] loss: 0.1919148\n",
      "[133,   150] loss: 0.1292157\n",
      "[134,   150] loss: 0.1010959\n",
      "[135,   150] loss: 0.2055750\n",
      "[136,   150] loss: 0.1267517\n",
      "[137,   150] loss: 0.1254617\n",
      "[138,   150] loss: 0.0917066\n",
      "[139,   150] loss: 0.0766930\n",
      "[140,   150] loss: 0.0677233\n",
      "[141,   150] loss: 0.0663237\n",
      "[142,   150] loss: 0.0557833\n",
      "[143,   150] loss: 0.0590120\n",
      "[144,   150] loss: 0.0451706\n",
      "[145,   150] loss: 0.0524920\n",
      "[146,   150] loss: 0.0637589\n",
      "[147,   150] loss: 0.0630888\n",
      "[148,   150] loss: 0.1565344\n",
      "[149,   150] loss: 0.1384732\n",
      "Finished Training\n",
      "Error rate of test images: 0.000000\n",
      "AE error rate : 0.000000 \n",
      "save model data/[2021-12-28_19-43-47]_best_model_final_5.pth\n",
      "[0,   150] loss: 0.6912090\n",
      "[1,   150] loss: 0.6714117\n",
      "[2,   150] loss: 0.6538294\n",
      "[3,   150] loss: 0.6376838\n",
      "[4,   150] loss: 0.6227630\n",
      "[5,   150] loss: 0.6087370\n",
      "[6,   150] loss: 0.5952879\n",
      "[7,   150] loss: 0.5819607\n",
      "[8,   150] loss: 0.5683105\n",
      "[9,   150] loss: 0.5547956\n",
      "[10,   150] loss: 0.5415100\n",
      "[11,   150] loss: 0.5287268\n",
      "[12,   150] loss: 0.5159091\n",
      "[13,   150] loss: 0.5031552\n",
      "[14,   150] loss: 0.4909523\n",
      "[15,   150] loss: 0.4807026\n",
      "[16,   150] loss: 0.4738017\n",
      "[17,   150] loss: 0.4698616\n",
      "[18,   150] loss: 0.4685005\n",
      "[19,   150] loss: 0.4676556\n",
      "[20,   150] loss: 0.4678890\n",
      "[21,   150] loss: 0.4675851\n",
      "[22,   150] loss: 0.4675346\n",
      "[23,   150] loss: 0.4676960\n",
      "[24,   150] loss: 0.4676989\n",
      "[25,   150] loss: 0.4678270\n",
      "[26,   150] loss: 0.4672691\n",
      "[27,   150] loss: 0.4670298\n",
      "[28,   150] loss: 0.4666422\n",
      "[29,   150] loss: 0.4666344\n",
      "[30,   150] loss: 0.4669273\n",
      "[31,   150] loss: 0.4670121\n",
      "[32,   150] loss: 0.4670873\n",
      "[33,   150] loss: 0.4665365\n",
      "[34,   150] loss: 0.4666886\n",
      "[35,   150] loss: 0.4659439\n",
      "[36,   150] loss: 0.4664456\n",
      "[37,   150] loss: 0.4667354\n",
      "[38,   150] loss: 0.4660557\n",
      "[39,   150] loss: 0.4654708\n",
      "[40,   150] loss: 0.4652967\n",
      "[41,   150] loss: 0.4661924\n",
      "[42,   150] loss: 0.4657883\n",
      "[43,   150] loss: 0.4642952\n",
      "[44,   150] loss: 0.4663287\n",
      "[45,   150] loss: 0.4650901\n",
      "[46,   150] loss: 0.4651730\n",
      "[47,   150] loss: 0.4644924\n",
      "[48,   150] loss: 0.4642415\n",
      "[49,   150] loss: 0.4648035\n",
      "[50,   150] loss: 0.4638528\n",
      "[51,   150] loss: 0.4646440\n",
      "[52,   150] loss: 0.4635249\n",
      "[53,   150] loss: 0.4638948\n",
      "[54,   150] loss: 0.4629881\n",
      "[55,   150] loss: 0.4634610\n",
      "[56,   150] loss: 0.4624755\n",
      "[57,   150] loss: 0.4626554\n",
      "[58,   150] loss: 0.4619434\n",
      "[59,   150] loss: 0.4616198\n",
      "[60,   150] loss: 0.4620271\n",
      "[61,   150] loss: 0.4604892\n",
      "[62,   150] loss: 0.4614675\n",
      "[63,   150] loss: 0.4592500\n",
      "[64,   150] loss: 0.4596451\n",
      "[65,   150] loss: 0.4596766\n",
      "[66,   150] loss: 0.4582173\n",
      "[67,   150] loss: 0.4582498\n",
      "[68,   150] loss: 0.4557659\n",
      "[69,   150] loss: 0.4578011\n",
      "[70,   150] loss: 0.4560762\n",
      "[71,   150] loss: 0.4552924\n",
      "[72,   150] loss: 0.4540491\n",
      "[73,   150] loss: 0.4540277\n",
      "[74,   150] loss: 0.4520220\n",
      "[75,   150] loss: 0.4515595\n",
      "[76,   150] loss: 0.4490079\n",
      "[77,   150] loss: 0.4468102\n",
      "[78,   150] loss: 0.4460940\n",
      "[79,   150] loss: 0.4432890\n",
      "[80,   150] loss: 0.4418045\n",
      "[81,   150] loss: 0.4378585\n",
      "[82,   150] loss: 0.4344220\n",
      "[83,   150] loss: 0.4307910\n",
      "[84,   150] loss: 0.4254590\n",
      "[85,   150] loss: 0.4182902\n",
      "[86,   150] loss: 0.4132705\n",
      "[87,   150] loss: 0.4026285\n",
      "[88,   150] loss: 0.3944094\n",
      "[89,   150] loss: 0.3855644\n",
      "[90,   150] loss: 0.3588860\n",
      "[91,   150] loss: 0.3500750\n",
      "[92,   150] loss: 0.3199957\n",
      "[93,   150] loss: 0.2933351\n",
      "[94,   150] loss: 0.2723811\n",
      "[95,   150] loss: 0.2219049\n",
      "[96,   150] loss: 0.2111625\n",
      "[97,   150] loss: 0.2094406\n",
      "[98,   150] loss: 0.1399401\n",
      "[99,   150] loss: 0.1018509\n",
      "[100,   150] loss: 0.0678061\n",
      "[101,   150] loss: 0.0328940\n",
      "[102,   150] loss: 0.0228057\n",
      "[103,   150] loss: 0.0170066\n",
      "[104,   150] loss: 0.0132499\n",
      "[105,   150] loss: 0.0101522\n",
      "[106,   150] loss: 0.0081046\n",
      "[107,   150] loss: 0.0068268\n",
      "[108,   150] loss: 0.0058954\n",
      "[109,   150] loss: 0.0050495\n",
      "[110,   150] loss: 0.0043983\n",
      "[111,   150] loss: 0.0037988\n",
      "[112,   150] loss: 0.0033802\n",
      "[113,   150] loss: 0.0030756\n",
      "[114,   150] loss: 0.0027934\n",
      "[115,   150] loss: 0.0025732\n",
      "[116,   150] loss: 0.0023609\n",
      "[117,   150] loss: 0.0021601\n",
      "[118,   150] loss: 0.0019847\n",
      "[119,   150] loss: 0.0018646\n",
      "[120,   150] loss: 0.0017517\n",
      "[121,   150] loss: 0.0016414\n",
      "[122,   150] loss: 0.0015323\n",
      "[123,   150] loss: 0.0014496\n",
      "[124,   150] loss: 0.0013545\n",
      "[125,   150] loss: 0.0012855\n",
      "[126,   150] loss: 0.0012177\n",
      "[127,   150] loss: 0.0011834\n",
      "[128,   150] loss: 0.0011141\n",
      "[129,   150] loss: 0.0010637\n",
      "[130,   150] loss: 0.0010102\n",
      "[131,   150] loss: 0.0009670\n",
      "[132,   150] loss: 0.0009278\n",
      "[133,   150] loss: 0.0008952\n",
      "[134,   150] loss: 0.0008579\n",
      "[135,   150] loss: 0.0008161\n",
      "[136,   150] loss: 0.0007912\n",
      "[137,   150] loss: 0.0007693\n",
      "[138,   150] loss: 0.0007332\n",
      "[139,   150] loss: 0.0007098\n",
      "[140,   150] loss: 0.0006895\n",
      "[141,   150] loss: 0.0006586\n",
      "[142,   150] loss: 0.0006443\n",
      "[143,   150] loss: 0.0006224\n",
      "[144,   150] loss: 0.0006075\n",
      "[145,   150] loss: 0.0005939\n",
      "[146,   150] loss: 0.0005695\n",
      "[147,   150] loss: 0.0005551\n",
      "[148,   150] loss: 0.0005410\n",
      "[149,   150] loss: 0.0005220\n",
      "Finished Training\n",
      "Error rate of test images: 0.000000\n",
      "AE error rate : 0.034483 \n",
      "save model data/[2021-12-28_19-43-47]_best_model_final_6.pth\n",
      "[0,   150] loss: 0.6294371\n",
      "[1,   150] loss: 0.6017507\n",
      "[2,   150] loss: 0.5789829\n",
      "[3,   150] loss: 0.5556840\n",
      "[4,   150] loss: 0.5322719\n",
      "[5,   150] loss: 0.5041893\n",
      "[6,   150] loss: 0.4698791\n",
      "[7,   150] loss: 0.4239077\n",
      "[8,   150] loss: 0.4092541\n",
      "[9,   150] loss: 0.4112040\n",
      "[10,   150] loss: 0.4063226\n",
      "[11,   150] loss: 0.4055277\n",
      "[12,   150] loss: 0.4075533\n",
      "[13,   150] loss: 0.4085039\n",
      "[14,   150] loss: 0.4048052\n",
      "[15,   150] loss: 0.4047368\n",
      "[16,   150] loss: 0.4049301\n",
      "[17,   150] loss: 0.4036203\n",
      "[18,   150] loss: 0.4060676\n",
      "[19,   150] loss: 0.4033864\n",
      "[20,   150] loss: 0.4012651\n",
      "[21,   150] loss: 0.4019521\n",
      "[22,   150] loss: 0.4026368\n",
      "[23,   150] loss: 0.4016310\n",
      "[24,   150] loss: 0.3999687\n",
      "[25,   150] loss: 0.4012047\n",
      "[26,   150] loss: 0.3992574\n",
      "[27,   150] loss: 0.4002431\n",
      "[28,   150] loss: 0.4029587\n",
      "[29,   150] loss: 0.4026495\n",
      "[30,   150] loss: 0.3955519\n",
      "[31,   150] loss: 0.3956449\n",
      "[32,   150] loss: 0.3908752\n",
      "[33,   150] loss: 0.3947198\n",
      "[34,   150] loss: 0.3926058\n",
      "[35,   150] loss: 0.3863413\n",
      "[36,   150] loss: 0.3876033\n",
      "[37,   150] loss: 0.3781611\n",
      "[38,   150] loss: 0.3771687\n",
      "[39,   150] loss: 0.3768982\n",
      "[40,   150] loss: 0.3668206\n",
      "[41,   150] loss: 0.3613986\n",
      "[42,   150] loss: 0.3526077\n",
      "[43,   150] loss: 0.3352054\n",
      "[44,   150] loss: 0.3275411\n",
      "[45,   150] loss: 0.3101063\n",
      "[46,   150] loss: 0.2749466\n",
      "[47,   150] loss: 0.2891826\n",
      "[48,   150] loss: 0.2385008\n",
      "[49,   150] loss: 0.2670729\n",
      "[50,   150] loss: 0.1862886\n",
      "[51,   150] loss: 0.1422180\n",
      "[52,   150] loss: 0.1815379\n",
      "[53,   150] loss: 0.0653398\n",
      "[54,   150] loss: 0.0693957\n",
      "[55,   150] loss: 0.0327772\n",
      "[56,   150] loss: 0.0186079\n",
      "[57,   150] loss: 0.0119101\n",
      "[58,   150] loss: 0.0093652\n",
      "[59,   150] loss: 0.0068073\n",
      "[60,   150] loss: 0.0057636\n",
      "[61,   150] loss: 0.0050123\n",
      "[62,   150] loss: 0.0040502\n",
      "[63,   150] loss: 0.0035928\n",
      "[64,   150] loss: 0.0032435\n",
      "[65,   150] loss: 0.0027919\n",
      "[66,   150] loss: 0.0025177\n",
      "[67,   150] loss: 0.0022423\n",
      "[68,   150] loss: 0.0021668\n",
      "[69,   150] loss: 0.0019025\n",
      "[70,   150] loss: 0.0017246\n",
      "[71,   150] loss: 0.0016257\n",
      "[72,   150] loss: 0.0014963\n",
      "[73,   150] loss: 0.0013952\n",
      "[74,   150] loss: 0.0013156\n",
      "[75,   150] loss: 0.0012214\n",
      "[76,   150] loss: 0.0011511\n",
      "[77,   150] loss: 0.0010886\n",
      "[78,   150] loss: 0.0010265\n",
      "[79,   150] loss: 0.0009836\n",
      "[80,   150] loss: 0.0009278\n",
      "[81,   150] loss: 0.0008431\n",
      "[82,   150] loss: 0.0008437\n",
      "[83,   150] loss: 0.0007971\n",
      "[84,   150] loss: 0.0007599\n",
      "[85,   150] loss: 0.0007417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86,   150] loss: 0.0007110\n",
      "[87,   150] loss: 0.0006721\n",
      "[88,   150] loss: 0.0006633\n",
      "[89,   150] loss: 0.0006234\n",
      "[90,   150] loss: 0.0006123\n",
      "[91,   150] loss: 0.0005874\n",
      "[92,   150] loss: 0.0005646\n",
      "[93,   150] loss: 0.0005477\n",
      "[94,   150] loss: 0.0005302\n",
      "[95,   150] loss: 0.0005124\n",
      "[96,   150] loss: 0.0004927\n",
      "[97,   150] loss: 0.0004813\n",
      "[98,   150] loss: 0.0004642\n",
      "[99,   150] loss: 0.0004547\n",
      "[100,   150] loss: 0.0004402\n",
      "[101,   150] loss: 0.0004277\n",
      "[102,   150] loss: 0.0004138\n",
      "[103,   150] loss: 0.0004061\n",
      "[104,   150] loss: 0.0003965\n",
      "[105,   150] loss: 0.0003860\n",
      "[106,   150] loss: 0.0003725\n",
      "[107,   150] loss: 0.0003647\n",
      "[108,   150] loss: 0.0003575\n",
      "[109,   150] loss: 0.0003477\n",
      "[110,   150] loss: 0.0003418\n",
      "[111,   150] loss: 0.0003330\n",
      "[112,   150] loss: 0.0003262\n",
      "[113,   150] loss: 0.0003163\n",
      "[114,   150] loss: 0.0003147\n",
      "[115,   150] loss: 0.0003087\n",
      "[116,   150] loss: 0.0002974\n",
      "[117,   150] loss: 0.0002919\n",
      "[118,   150] loss: 0.0002893\n",
      "[119,   150] loss: 0.0002793\n",
      "[120,   150] loss: 0.0002774\n",
      "[121,   150] loss: 0.0002702\n",
      "[122,   150] loss: 0.0002631\n",
      "[123,   150] loss: 0.0002588\n",
      "[124,   150] loss: 0.0002548\n",
      "[125,   150] loss: 0.0002521\n",
      "[126,   150] loss: 0.0002452\n",
      "[127,   150] loss: 0.0002415\n",
      "[128,   150] loss: 0.0002368\n",
      "[129,   150] loss: 0.0002338\n",
      "[130,   150] loss: 0.0002309\n",
      "[131,   150] loss: 0.0002254\n",
      "[132,   150] loss: 0.0002221\n",
      "[133,   150] loss: 0.0002179\n",
      "[134,   150] loss: 0.0002146\n",
      "[135,   150] loss: 0.0002135\n",
      "[136,   150] loss: 0.0002087\n",
      "[137,   150] loss: 0.0002057\n",
      "[138,   150] loss: 0.0002010\n",
      "[139,   150] loss: 0.0001989\n",
      "[140,   150] loss: 0.0001964\n",
      "[141,   150] loss: 0.0001933\n",
      "[142,   150] loss: 0.0001897\n",
      "[143,   150] loss: 0.0001873\n",
      "[144,   150] loss: 0.0001842\n",
      "[145,   150] loss: 0.0001839\n",
      "[146,   150] loss: 0.0001785\n",
      "[147,   150] loss: 0.0001771\n",
      "[148,   150] loss: 0.0001748\n",
      "[149,   150] loss: 0.0001731\n",
      "Finished Training\n",
      "Error rate of test images: 0.000000\n",
      "AE error rate : 0.078947 \n",
      "save model data/[2021-12-28_19-43-47]_best_model_final_7.pth\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "for number, dsize in enumerate(data_size, 0):\n",
    "    train_loader1 = torch.utils.data.DataLoader(list(abnormal_images)[:dsize] + normal_image_list, batch_size=batch_size, shuffle = True)\n",
    "    test_loader1 = torch.utils.data.DataLoader(list(abnormal_images)[:dsize] + normal_image_list, batch_size=batch_size, shuffle = False)\n",
    "    val_loader1 = torch.utils.data.DataLoader(list(abnormal_images)[:dsize], batch_size=batch_size, shuffle = False)\n",
    "    \n",
    "    model = CNN()\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    file_name = f\"data/[{now}]_best_model_final_{number}.pth\"\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader1, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            cnn_loss = criterion(outputs, labels)\n",
    "            cnn_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += cnn_loss.item()\n",
    "            \n",
    "        print('[%d, %5d] loss: %.7f' %(epoch, num_epochs, running_loss/len(train_loader1)))\n",
    "\n",
    "    print('Finished Training')\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        error = 0\n",
    "        total = 0\n",
    "        \n",
    "        for data in test_loader1:\n",
    "            images, labels = data\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            # calculate outputs by running images through the network \n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            error += (predicted != labels).sum().item()\n",
    "\n",
    "        cnn_err_rate.append(error/len(test_loader1))\n",
    "        print('Error rate of test images: %f' % (error / total))\n",
    "\n",
    "\n",
    "    ae_err = 0\n",
    "    for data in val_loader1:\n",
    "        images, labels = data\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "        output = AE(images)\n",
    "        ae_loss = ae_criterion(images, output)\n",
    "\n",
    "        if ae_loss.item() < threshold:\n",
    "            ae_err += 1\n",
    "\n",
    "    ae_err_rate.append(ae_err / len(val_loader1))\n",
    "    print('AE error rate : %.6f ' % (ae_err / len(val_loader1)))\n",
    "\n",
    "    torch.save(model.state_dict(), file_name)\n",
    "    print(\"save model \" + file_name)\n",
    "\n",
    "    with open(f'[{now}]-error-rate.txt', 'a') as f:\n",
    "        f.write(f'{dsize} {error/len(test_loader1)} {ae_err / len(val_loader1)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b3e8798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(f'[{now}]-error-rate.txt', 'r') as f:\n",
    "    data = f.readlines()\n",
    "    \n",
    "    num_abnormal = list()\n",
    "    cnn_err_rate = list()\n",
    "    ae_err_rate = list()\n",
    "    for index in data:\n",
    "        num, cnn, ae = tuple(map(float, index.split()))\n",
    "        num_abnormal.append(num)\n",
    "        cnn_err_rate.append(cnn)\n",
    "        ae_err_rate.append(ae)\n",
    "        \n",
    "    plt.plot(num_abnormal, cnn_err_rate, label = 'CNN')\n",
    "    plt.plot(num_abnormal, ae_err_rate, label = 'CAE')\n",
    "    plt.xlabel('Number of abnormal data')\n",
    "    plt.ylabel('error rate')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaf9fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9d5f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
