{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b63b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5125853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "batch_size = 8\n",
    "num_epochs = 50\n",
    "learning_rate = 0.0011\n",
    "data_size = [100, 300, 600, 900, 1200, 1500, 2300]\n",
    "\n",
    "normal_dir = 'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\캡디이미지\\\\CAE_dataset\\\\normal'\n",
    "abnormal_dir = 'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\캡디이미지\\\\CAE_dataset\\\\abnormal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2706f558",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_images = datasets.ImageFolder(\n",
    "    normal_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "abnormal_images = datasets.ImageFolder(\n",
    "    abnormal_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "    \n",
    "\n",
    "labeled_abnormal_images = []\n",
    "for feature, index in abnormal_images:\n",
    "    labeled_abnormal_images.append([feature, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a99d60c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 12, 5) \n",
    "        self.conv3 = nn.Conv2d(12, 24, 4)  \n",
    "        self.fc1 = nn.Linear(24 * 25 * 25, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # 6 * 110 * 110\n",
    "        x = self.pool(F.relu(self.conv2(x))) # 12 * 53 * 53\n",
    "        x = self.pool(F.relu(self.conv3(x))) # 24 * 25 * 25\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "640c200d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of abnormal data : 100\n",
      "[0/50] loss : 0.7250301480293274\n",
      "[10/50] loss : 0.6187043702602386\n",
      "[20/50] loss : 0.5767399391531944\n",
      "[30/50] loss : 0.5763492518663407\n",
      "[40/50] loss : 0.5759631159901619\n",
      "save model CNN_best_model_0.pth \n",
      "\n",
      "Number of abnormal data : 300\n",
      "[0/50] loss : 0.6923602135976156\n",
      "[10/50] loss : 0.692968369325002\n",
      "[20/50] loss : 0.6928785689671835\n",
      "[30/50] loss : 0.6927122036616008\n",
      "[40/50] loss : 0.6924572745958965\n",
      "save model CNN_best_model_1.pth \n",
      "\n",
      "Number of abnormal data : 600\n",
      "[0/50] loss : 0.6844152217464787\n",
      "[10/50] loss : 0.610640885441431\n",
      "[20/50] loss : 0.435190885494064\n",
      "[30/50] loss : 0.2526887259612392\n",
      "[40/50] loss : 0.06587739818600571\n",
      "save model CNN_best_model_2.pth \n",
      "\n",
      "Number of abnormal data : 900\n",
      "[0/50] loss : 0.7075090209643046\n",
      "[10/50] loss : 0.5007971621553103\n",
      "[20/50] loss : 0.45376778083542985\n",
      "[30/50] loss : 0.3327189119470616\n",
      "[40/50] loss : 0.2835446327909206\n",
      "save model CNN_best_model_3.pth \n",
      "\n",
      "Number of abnormal data : 1200\n",
      "[0/50] loss : 0.685674040075292\n",
      "[10/50] loss : 0.4481986283877476\n",
      "[20/50] loss : 0.2120103235244452\n",
      "[30/50] loss : 0.06709941528659105\n",
      "[40/50] loss : 0.013944481390081396\n",
      "save model CNN_best_model_4.pth \n",
      "\n",
      "Number of abnormal data : 1500\n",
      "[0/50] loss : 0.6046858315997653\n",
      "[10/50] loss : 0.34563966541654534\n",
      "[20/50] loss : 0.2731250594018234\n",
      "[30/50] loss : 0.21930569460718996\n",
      "[40/50] loss : 0.1929417528046502\n",
      "save model CNN_best_model_5.pth \n",
      "\n",
      "Number of abnormal data : 2300\n",
      "[0/50] loss : 0.6512950605154038\n",
      "[10/50] loss : 0.2012090122179749\n",
      "[20/50] loss : 0.09238955455288912\n",
      "[30/50] loss : 0.028100726165866945\n",
      "[40/50] loss : 0.008064390666792558\n",
      "save model CNN_best_model_6.pth \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for number, dsize in enumerate(data_size, 0):\n",
    "    \n",
    "    CNN_PATH = f'CNN_model/CNN_best_model_{number}.pth'\n",
    "    \n",
    "    print(f\"Number of abnormal data : {dsize}\")\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(normal_images + labeled_abnormal_images[:dsize], batch_size=batch_size)\n",
    "    test_loader = torch.utils.data.DataLoader(normal_images + labeled_abnormal_images[:dsize], batch_size=batch_size, shuffle = True)\n",
    "    \n",
    "    cnn = CNN()\n",
    "    cnn.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.SGD(cnn.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = cnn(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"[{epoch}/{num_epochs}] loss : {running_loss / len(train_loader)}\")\n",
    "    \n",
    "    torch.save(cnn.state_dict(), CNN_PATH)\n",
    "    print(\"save model \" + CNN_PATH ,\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
