{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6394ddf",
   "metadata": {},
   "source": [
    "***Import library***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3f6f48c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d931211",
   "metadata": {},
   "source": [
    "***Hyper Parameters***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c92b1d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00296401 0.00122346 0.00115846 0.00115846 0.00115846 0.00115846\n",
      " 0.00115846]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "batch_size = 8\n",
    "learning_rate = 0.0011\n",
    "\n",
    "with open(f'data/threshold.txt', 'r') as f:\n",
    "    data = f.readlines()\n",
    "    threshold_list = []\n",
    "    \n",
    "    for index in data:\n",
    "        threshold = tuple(map(float, index.split()))\n",
    "        threshold_list.append(threshold)\n",
    "    threshold_list = np.concatenate(threshold_list)\n",
    "    print(threshold_list)\n",
    "    \n",
    "data_size = [100, 300, 600, 900, 1200, 1500, 2300]\n",
    "\n",
    "normal_dir = 'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\캡디이미지\\\\CAE_dataset\\\\normal'\n",
    "abnormal_dir = 'C:\\\\Users\\\\WorkStation\\\\Desktop\\\\캡디이미지\\\\CAE_dataset\\\\abnormal'\n",
    "AE_PATH = 'CAE_best_model.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5434c625",
   "metadata": {},
   "source": [
    "***Load Datasets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "866e5582",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_images = datasets.ImageFolder(\n",
    "    normal_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "abnormal_images = datasets.ImageFolder(\n",
    "    abnormal_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "    \n",
    "\n",
    "labeled_normal_images = []\n",
    "for feature, index in normal_images:\n",
    "    labeled_normal_images.append([feature, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e8641",
   "metadata": {},
   "source": [
    "***Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66205f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 12, 5) \n",
    "        self.conv3 = nn.Conv2d(12, 24, 4)  \n",
    "        self.fc1 = nn.Linear(24 * 25 * 25, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # 6 * 110 * 110\n",
    "        x = self.pool(F.relu(self.conv2(x))) # 12 * 53 * 53\n",
    "        x = self.pool(F.relu(self.conv3(x))) # 24 * 25 * 25\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fe075779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvAutoEncoder(\n",
       "  (cnn_layer1): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (cnn_layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (cnn_layer3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (tran_cnn_layer1): Sequential(\n",
       "    (0): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (tran_cnn_layer2): Sequential(\n",
       "    (0): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (tran_cnn_layer3): Sequential(\n",
       "    (0): ConvTranspose2d(16, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.cnn_layer1 = nn.Sequential(\n",
    "                        nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                         nn.MaxPool2d(2,2))\n",
    "\n",
    "        self.cnn_layer2 = nn.Sequential(\n",
    "                                nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                 nn.MaxPool2d(2,2))\n",
    "        \n",
    "        self.cnn_layer3 = nn.Sequential(\n",
    "                                nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                 nn.MaxPool2d(2,2))\n",
    "\n",
    "        # Decoder        \n",
    "        self.tran_cnn_layer1 = nn.Sequential(\n",
    "                        nn.ConvTranspose2d(64, 32, kernel_size = 2, stride = 2, padding=0),\n",
    "                        nn.ReLU())\n",
    "        \n",
    "        self.tran_cnn_layer2 = nn.Sequential(\n",
    "                        nn.ConvTranspose2d(32, 16, kernel_size = 2, stride = 2, padding=0),\n",
    "                        nn.ReLU())\n",
    "\n",
    "        self.tran_cnn_layer3 = nn.Sequential(\n",
    "                        nn.ConvTranspose2d(16, 3, kernel_size = 2, stride = 2, padding=0),\n",
    "                        nn.Sigmoid())  \n",
    "            \n",
    "    def forward(self, x):\n",
    "        output = self.cnn_layer1(x)\n",
    "        output = self.cnn_layer2(output)\n",
    "        output = self.cnn_layer3(output)        \n",
    "        output = self.tran_cnn_layer1(output)\n",
    "        output = self.tran_cnn_layer2(output)\n",
    "        output = self.tran_cnn_layer3(output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "AE = ConvAutoEncoder()\n",
    "AE.load_state_dict(torch.load(AE_PATH))\n",
    "AE.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3b37db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_criterion = nn.MSELoss()\n",
    "cnn_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79796071",
   "metadata": {},
   "source": [
    "***Train & Test***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "36fcc445",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of abnormal data : 100\n",
      "CNN error rate : 1.0\n",
      "AE error rate : 0.0\n",
      "\n",
      "Number of abnormal data : 300\n",
      "CNN error rate : 0.4966442953020134\n",
      "AE error rate : 0.0\n",
      "\n",
      "Number of abnormal data : 600\n",
      "CNN error rate : 0.9988839285714286\n",
      "AE error rate : 0.002232142857142857\n",
      "\n",
      "Number of abnormal data : 900\n",
      "CNN error rate : 1.0\n",
      "AE error rate : 0.0016722408026755853\n",
      "\n",
      "Number of abnormal data : 1200\n",
      "CNN error rate : 0.9986631016042781\n",
      "AE error rate : 0.001336898395721925\n",
      "\n",
      "Number of abnormal data : 1500\n",
      "CNN error rate : 0.9988864142538976\n",
      "AE error rate : 0.0011135857461024498\n",
      "\n",
      "Number of abnormal data : 2300\n",
      "CNN error rate : 0.9995826377295493\n",
      "AE error rate : 0.0008347245409015025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_err_rate = []\n",
    "ae_err_rate = []\n",
    "\n",
    "for number, dsize in enumerate (data_size):\n",
    "    train_loader = torch.utils.data.DataLoader(labeled_normal_images + list(abnormal_images)[:dsize], batch_size=batch_size)\n",
    "    CNN_test_loader = torch.utils.data.DataLoader(labeled_normal_images + list(abnormal_images)[:dsize], batch_size=batch_size, shuffle = True)\n",
    "    CAE_test_loader = torch.utils.data.DataLoader(labeled_normal_images + list(abnormal_images)[:dsize], batch_size=1, shuffle = True)\n",
    "    \n",
    "    CNN_PATH = f\"CNN_model/CNN_best_model_{number}.pth\"\n",
    "    cnn.load_state_dict(torch.load(CNN_PATH))\n",
    "    cnn.to(device)\n",
    "    print(f\"Number of abnormal data : {dsize}\")\n",
    "    \n",
    "    error = 0\n",
    "    total = 0\n",
    "    ##### CNN #####\n",
    "    for data in CNN_test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = cnn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        error += (predicted != labels).sum().item()\n",
    "        \n",
    "    print(f\"CNN error rate : {error / total}\")        \n",
    "    cnn_err_rate.append(error / total)\n",
    "        \n",
    "\n",
    "    ae_err = 0    \n",
    "    ##### CAE #####\n",
    "    for data in CAE_test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        output = AE(images)\n",
    "        ae_loss = ae_criterion(images, output)\n",
    "    \n",
    "        if labels == 0 and ae_loss.item() < threshold_list[number]:\n",
    "            ae_err += 1\n",
    "        elif labels == 1 and ae_loss.item() > threshold_list[number]:\n",
    "            ae_err += 1\n",
    "    \n",
    "    ae_err_rate.append(ae_err / len(CAE_test_loader))\n",
    "    print(f\"AE error rate : {ae_err / len(CAE_test_loader)}\\n\")       \n",
    "\n",
    "    with open(f'data/error-rate.txt', 'a') as f:\n",
    "        f.write(f'{dsize} {error/total} {ae_err / len(CAE_test_loader)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b062e413",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e24327a",
   "metadata": {},
   "source": [
    "***Graph***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7b3e8798",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/rror-rate.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-fec4ae4d4c78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'data/rror-rate.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnum_abnormal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcnn_err_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/rror-rate.txt'"
     ]
    }
   ],
   "source": [
    "#with open(f'data/error-rate.txt', 'r') as f:\n",
    "#    data = f.readlines()\n",
    "#    \n",
    "#    num_abnormal = []\n",
    "#    cnn_err_rate = []\n",
    "#    ae_err_rate = []\n",
    "#    \n",
    "#    for index in data:\n",
    "#        num, cnn, ae = tuple(map(float, index.split()))\n",
    "#        \n",
    "#        num_abnormal.append(num)\n",
    "#        cnn_err_rate.append(cnn)\n",
    "#        ae_err_rate.append(ae)\n",
    "\n",
    "plt.plot(data_size, cnn_err_rate, label = 'CNN')\n",
    "plt.plot(data_size, ae_err_rate, label = 'CAE')\n",
    "plt.xlabel('Number of abnormal data')\n",
    "plt.ylabel('error rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2b8941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
